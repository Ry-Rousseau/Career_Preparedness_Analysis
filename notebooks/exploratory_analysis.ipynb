{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1d77ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: missingno in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2024.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from missingno) (1.15.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (2.0.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastparquet) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn missingno plotly openpyxl pyarrow fastparquet\n",
    "\n",
    "# load all packages for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "\n",
    "# load the data\n",
    "data = pd.read_excel(\"../data/CDS_25_Task1.xlsx\", sheet_name='Data', header=1, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3dff3",
   "metadata": {},
   "source": [
    "### Emotional, workplace, and environmental factor codes\n",
    "| Group | Subgroup | Statement | Fast Choice Keys | Likert Keys |\n",
    "|-------|----------|-----------|------------------|-------------|\n",
    "| Emotional | General | I'm ready for my next step | Fgen | Lgen |\n",
    "| Emotional | Transformation | I want a new start | FTraDes | LTraDes |\n",
    "| Emotional | Transformation | I've got freedom to change | FTraAut | LTraAut |\n",
    "| Emotional | Containers | I'm comfortable where I am | FCntCom | LCntCom |\n",
    "| Emotional | Containers | I feel like my voice is heard | FCntPsy | LCntPsy |\n",
    "| Emotional | Connection | Others influence my decisions | FConSoc | LConSoc |\n",
    "| Emotional | Balance | I'm anxious about change | FBalAnx | LBalAnx |\n",
    "| Emotional | Resources | I'm financially motivated | FResFin | LResFin |\n",
    "| Emotional | Control | I believe in myself | FContImp | LContImp |\n",
    "| Emotional | Journey | I'm optimistic about the future | FJouOpt | LJouOpt |\n",
    "| Emotional | Connection | I feel included | FConInc | LConInc |\n",
    "| Emotional | Balance | I'm happy where I am | FBalSat | LBalSat |\n",
    "| Emotional | Resources | I've got the skills to progress | FResSki | LResSki |\n",
    "| Emotional | Control | I control my next step | FContCon | LContCon |\n",
    "| Emotional | Journey | I've set myself goals | FJouPro | LJouPro |\n",
    "| Workplace/functional | Lack of opportunity to use skills/abilities | I can use my skills | FUseSkills | LUseSkills |\n",
    "| Workplace/functional | Learning and development | I have opportunities to learn | FLearnDev | LLearnDev |\n",
    "| Workplace/functional | Career advancement and promotions | I can grow here | Fcarprom | Lcarprom |\n",
    "| Workplace/functional | Meaning | I find my job meaningful | FMeanFull | LMeanFull |\n",
    "| Workplace/functional | Poor management | My manager is poor | Fpoorman | Lpoorman |\n",
    "| Workplace/functional | Toxic workplace/Company culture | The work culture is toxic | Ftoxic | Ltoxic |\n",
    "| Workplace/functional | Excessive or too little work | I'm working too hard | FExcessWk | LExcessWk |\n",
    "| Workplace/functional | Disagreement or fall out with colleagues | I don't get along with my colleagues | Fcollea | Lcollea |\n",
    "| Workplace/functional | A better salary and financial stability | I'm well compensated | Fwellcomp | Lwellcomp |\n",
    "| Workplace/functional | Financial fairness | My salary is unfair compared to colleagues | FFinFair | LFinLair |\n",
    "| Workplace/functional | Satisfaction around hybrid working | I enjoy hybrid working | Fenjhyb | Lenjhyb |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfa66a",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Firstly, clean our variable names, set our data types, and re-save the data for future loading/processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9a4a7499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4211, 67)\n",
      "Data columns: Index(['batc_unnamed:_0', 'gend_unnamed:_1', 'age_unnamed:_2',\n",
      "       'pers_extraverted,_enthusiastic.', 'pers_critical,_quarrelsome.',\n",
      "       'pers_dependable,_self-disciplined.', 'pers_anxious,_easily_upset.',\n",
      "       'pers_open_to_new_experiences,_complex.', 'pers_sympathetic,_warm.',\n",
      "       'pers_disorganized,_careless.', 'pers_reserved,_quiet.',\n",
      "       'pers_calm,_emotionally_stable.', 'pers_conventional,_uncreative.',\n",
      "       'prep_unnamed:_13', 'qual_unnamed:_14',\n",
      "       'emot_emotional_likert.lbal_anx_', 'emot_emotional_likert.lbal_sat_',\n",
      "       'emot_emotional_likert.lcnt_com_', 'emot_emotional_likert.lcnt_psy_',\n",
      "       'emot_emotional_likert.lcon_inc_', 'emot_emotional_likert.lcon_soc_',\n",
      "       'emot_emotional_likert.lcont_con__',\n",
      "       'emot_emotional_likert.lcont_imp__', 'emot_emotional_likert.lgen__',\n",
      "       'emot_emotional_likert.ljou_opt__', 'emot_emotional_likert.ljou_pro__',\n",
      "       'emot_emotional_likert.lres_fin__', 'emot_emotional_likert.lres_ski__',\n",
      "       'emot_emotional_likert.ltra_aut__', 'emot_emotional_likert.ltra_des__',\n",
      "       'work_functional_likert.lcarprom_d', 'work_functional_likert.lcollea_',\n",
      "       'work_functional_likert.lenjhyb_', 'work_functional_likert.lexcess_wk_',\n",
      "       'work_functional_likert.lfin_lair_',\n",
      "       'work_functional_likert.llearn_dev_',\n",
      "       'work_functional_likert.lmean_full_',\n",
      "       'work_functional_likert.lpoorman_', 'work_functional_likert.ltoxic_',\n",
      "       'work_functional_likert.luse_skills_',\n",
      "       'work_functional_likert.lwellcomp_',\n",
      "       'emot_emotional_statements.fbal_anx__',\n",
      "       'emot_emotional_statements.fbal_sat__',\n",
      "       'emot_emotional_statements.fcnt_com__',\n",
      "       'emot_emotional_statements.fcnt_psy__',\n",
      "       'emot_emotional_statements.fcon_inc__',\n",
      "       'emot_emotional_statements.fcon_soc__',\n",
      "       'emot_emotional_statements.fcont_con__',\n",
      "       'emot_emotional_statements.fcont_imp__',\n",
      "       'emot_emotional_statements.fgen__',\n",
      "       'emot_emotional_statements.fjou_opt__',\n",
      "       'emot_emotional_statements.fjou_pro__',\n",
      "       'emot_emotional_statements.fres_fin__',\n",
      "       'emot_emotional_statements.fres_ski__',\n",
      "       'emot_emotional_statements.ftra_aut__',\n",
      "       'emot_emotional_statements.ftra_des__',\n",
      "       'work_functional_statements.fcarprom_',\n",
      "       'work_functional_statements.fcollea',\n",
      "       'work_functional_statements.fenjhyb_',\n",
      "       'work_functional_statements.fexcess_wk',\n",
      "       'work_functional_statements.ffin_fair_',\n",
      "       'work_functional_statements.flearn_dev',\n",
      "       'work_functional_statements.fmean_full_',\n",
      "       'work_functional_statements.fpoorman_',\n",
      "       'work_functional_statements.ftoxic_',\n",
      "       'work_functional_statements.fuse_skills',\n",
      "       'work_functional_statements.fwellcomp_'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhrou\\AppData\\Local\\Temp\\ipykernel_56424\\3271360133.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  nrows=1, header=None).iloc[0].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the data\n",
    "data = pd.read_excel(\"../data/CDS_25_Task1.xlsx\", sheet_name='Data', \n",
    "                    header=1, index_col=False)\n",
    "\n",
    "# Quick rename with category prefixes\n",
    "cats = pd.read_excel(\"../data/CDS_25_Task1.xlsx\", sheet_name='Data', \n",
    "                    nrows=1, header=None).iloc[0].fillna(method='ffill')\n",
    "\n",
    "data.columns = [f\"{'pers' if 'personality' in str(cat).lower() else str(cat)[:4]}_{col}\".lower().replace(' ', '_') \n",
    "                for cat, col in zip(cats, data.columns)]\n",
    "\n",
    "data.head()\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "print(f\"Data columns: {data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e1a521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['batch', 'gender', 'age', 'pers_extraverted_enthusiastic',\n",
       "       'pers_critical_quarrelsome', 'pers_dependable_self-disciplined',\n",
       "       'pers_anxious_easily_upset', 'pers_open_to_new_experiences_complex',\n",
       "       'pers_sympathetic_warm', 'pers_disorganized_careless',\n",
       "       'pers_reserved_quiet', 'pers_calm_emotionally_stable',\n",
       "       'pers_conventional_uncreative', 'prep_level', 'qual_reasons',\n",
       "       'el_lbal_anx', 'el_lbal_sat', 'el_lcnt_com', 'el_lcnt_psy',\n",
       "       'el_lcon_inc', 'el_lcon_soc', 'el_lcont_con', 'el_lcont_imp', 'el_lgen',\n",
       "       'el_ljou_opt', 'el_ljou_pro', 'el_lres_fin', 'el_lres_ski',\n",
       "       'el_ltra_aut', 'el_ltra_des', 'wfl_lcarprom_d', 'wfl_lcollea',\n",
       "       'wfl_lenjhyb', 'wfl_lexcess_wk', 'wfl_lfin_lair', 'wfl_llearn_dev',\n",
       "       'wfl_lmean_full', 'wfl_lpoorman', 'wfl_ltoxic', 'wfl_luse_skills',\n",
       "       'wfl_lwellcomp', 'es_fbal_anx', 'es_fbal_sat', 'es_fcnt_com',\n",
       "       'es_fcnt_psy', 'es_fcon_inc', 'es_fcon_soc', 'es_fcont_con',\n",
       "       'es_fcont_imp', 'es_fgen', 'es_fjou_opt', 'es_fjou_pro', 'es_fres_fin',\n",
       "       'es_fres_ski', 'es_ftra_aut', 'es_ftra_des', 'wfs_fcarprom',\n",
       "       'wfs_fcollea', 'wfs_fenjhyb', 'wfs_fexcess_wk', 'wfs_ffin_fair',\n",
       "       'wfs_flearn_dev', 'wfs_fmean_full', 'wfs_fpoorman', 'wfs_ftoxic',\n",
       "       'wfs_fuse_skills', 'wfs_fwellcomp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean column names\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Clean dataframe column names using simple string operations\"\"\"\n",
    "    \n",
    "    # Create mapping dictionary\n",
    "    name_mapping = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        new_name = col\n",
    "        \n",
    "        # Handle specific replacements first\n",
    "        if col == 'batc_unnamed:_0':\n",
    "            new_name = 'batch'\n",
    "        elif col == 'gend_unnamed:_1':\n",
    "            new_name = 'gender'\n",
    "        elif col == 'age_unnamed:_2':\n",
    "            new_name = 'age'\n",
    "        elif col == 'prep_unnamed:_13':\n",
    "            new_name = 'prep_level'\n",
    "        elif col == 'qual_unnamed:_14':\n",
    "            new_name = 'qual_reasons'\n",
    "        else:\n",
    "            # Replace long prefixes with short codes\n",
    "            new_name = new_name.replace('emot_emotional_statements', 'es') # change to 'es' emotional statements (fast choice response)\n",
    "            new_name = new_name.replace('emot_emotional_likert', 'el') # change to workplace/functional likert, wfl\n",
    "            new_name = new_name.replace('work_functional_statements', 'wfs') #change workplace/functional statements (fast choice response)\n",
    "            new_name = new_name.replace('work_functional_likert', 'wfl') # change workplace/functional likert, wfl\n",
    "            \n",
    "            # Replace periods with underscores\n",
    "            new_name = new_name.replace('.', '_')\n",
    "            \n",
    "            # Remove commas\n",
    "            new_name = new_name.replace(',', '')\n",
    "            \n",
    "            # Remove trailing underscores\n",
    "            new_name = new_name.rstrip('_')\n",
    "        \n",
    "        name_mapping[col] = new_name\n",
    "    \n",
    "    # Apply the mapping\n",
    "    df_cleaned = df.rename(columns=name_mapping)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "data = clean_column_names(data)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9bec65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL VARIABLES ===\n",
      "batch: 7 unique values\n",
      "Values: ['FR Tech' 'DE Fin' 'SP Fin' 'US Pharma' 'IT Fin' 'UK Energy' 'US Tech']\n",
      "\n",
      "gender: 5 unique values\n",
      "Values: ['Female' 'Male' 'Non-Binary / Non-Conforming' 'Prefer Not to Answer'\n",
      " 'Other']\n",
      "\n",
      "age: 3 unique values\n",
      "Values: ['18-24' '25-40' '41-64']\n",
      "\n",
      "qual_reasons: 4107 unique values\n",
      "Values: ['Je suis prête à m’engager, organise'\n",
      " 'Jeune diplôme je suis prête à entrer dans le monde professionnel sur un emploi stable et sur du long terme'\n",
      " 'La nouvelle technologie, les nouveaux moyens mit en place…' ...\n",
      " 'Italian reasons' 'El Reasons' 'Reasons Spanish']\n",
      "\n",
      "=== PERSONALITY VARIABLES ===\n",
      "pers_extraverted_enthusiastic: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_critical_quarrelsome: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_dependable_self-disciplined: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_anxious_easily_upset: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_open_to_new_experiences_complex: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_sympathetic_warm: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_disorganized_careless: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_reserved_quiet: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_calm_emotionally_stable: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_conventional_uncreative: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "\n",
      "=== LIKERT VARIABLES ===\n",
      "el_lbal_anx: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lbal_sat: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcnt_com: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcnt_psy: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcon_inc: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcon_soc: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcont_con: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcont_imp: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lgen: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ljou_opt: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ljou_pro: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lres_fin: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lres_ski: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ltra_aut: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ltra_des: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lcarprom_d: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lcollea: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lenjhyb: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lexcess_wk: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_lfin_lair: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_llearn_dev: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lmean_full: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_lpoorman: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_ltoxic: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_luse_skills: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_lwellcomp: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "\n",
      "=== FACTOR VARIABLES ===\n",
      "es_fbal_anx: range -94.444 to 98.889, 512 unique values\n",
      "es_fbal_sat: range -96.667 to 98.889, 541 unique values\n",
      "es_fcnt_com: range -98.889 to 97.778, 547 unique values\n",
      "es_fcnt_psy: range -97.222 to 98.889, 530 unique values\n",
      "es_fcon_inc: range -98.889 to 97.778, 544 unique values\n",
      "es_fcon_soc: range -98.889 to 97.778, 507 unique values\n",
      "es_fcont_con: range -96.667 to 97.778, 510 unique values\n",
      "es_fcont_imp: range -98.889 to 98.889, 505 unique values\n",
      "es_fgen: range -96.667 to 98.889, 499 unique values\n",
      "es_fjou_opt: range -96.667 to 96.667, 549 unique values\n",
      "es_fjou_pro: range -98.889 to 96.667, 521 unique values\n",
      "es_fres_fin: range -98.889 to 98.889, 521 unique values\n",
      "es_fres_ski: range -98.889 to 98.889, 508 unique values\n",
      "es_ftra_aut: range -96.111 to 98.889, 520 unique values\n",
      "es_ftra_des: range -98.889 to 98.889, 513 unique values\n",
      "wfs_fcarprom: range 0.000 to 100.000, 177 unique values\n",
      "wfs_fcollea: range 0.000 to 100.000, 187 unique values\n",
      "wfs_fenjhyb: range 0.000 to 100.000, 189 unique values\n",
      "wfs_fexcess_wk: range 0.000 to 100.000, 185 unique values\n",
      "wfs_ffin_fair: range 0.000 to 100.000, 184 unique values\n",
      "wfs_flearn_dev: range 0.000 to 100.000, 174 unique values\n",
      "wfs_fmean_full: range 0.000 to 100.000, 180 unique values\n",
      "wfs_fpoorman: range 0.000 to 100.000, 189 unique values\n",
      "wfs_ftoxic: range 0.000 to 100.000, 185 unique values\n",
      "wfs_fuse_skills: range 0.000 to 100.000, 173 unique values\n",
      "wfs_fwellcomp: range 0.000 to 100.000, 183 unique values\n",
      "\n",
      "=== PREP LEVEL ===\n",
      "prep_level: 1.0 to 10.0\n",
      "Values: [np.float64(1.0), np.float64(1.1), np.float64(1.2), np.float64(1.3), np.float64(1.5), np.float64(1.7), np.float64(1.8), np.float64(1.9), np.float64(2.0), np.float64(2.1), np.float64(2.2), np.float64(2.3), np.float64(2.4), np.float64(2.6), np.float64(2.7), np.float64(2.8), np.float64(2.9), np.float64(3.0), np.float64(3.1), np.float64(3.2), np.float64(3.3), np.float64(3.4), np.float64(3.5), np.float64(3.6), np.float64(3.7), np.float64(3.8), np.float64(3.9), np.float64(4.0), np.float64(4.1), np.float64(4.2), np.float64(4.3), np.float64(4.4), np.float64(4.5), np.float64(4.6), np.float64(4.7), np.float64(4.8), np.float64(4.9), np.float64(5.0), np.float64(5.1), np.float64(5.2), np.float64(5.3), np.float64(5.4), np.float64(5.5), np.float64(5.6), np.float64(5.7), np.float64(5.8), np.float64(5.9), np.float64(6.0), np.float64(6.1), np.float64(6.2), np.float64(6.3), np.float64(6.4), np.float64(6.5), np.float64(6.6), np.float64(6.7), np.float64(6.8), np.float64(6.9), np.float64(7.0), np.float64(7.1), np.float64(7.2), np.float64(7.3), np.float64(7.4), np.float64(7.5), np.float64(7.6), np.float64(7.7), np.float64(7.8), np.float64(7.9), np.float64(8.0), np.float64(8.1), np.float64(8.2), np.float64(8.3), np.float64(8.4), np.float64(8.5), np.float64(8.6), np.float64(8.7), np.float64(8.8), np.float64(8.9), np.float64(9.0), np.float64(9.1), np.float64(9.2), np.float64(9.3), np.float64(9.4), np.float64(9.5), np.float64(9.6), np.float64(9.7), np.float64(9.8), np.float64(9.9), np.float64(10.0)]\n",
      "prep_level\n",
      "1.0      1\n",
      "1.1      2\n",
      "1.2      1\n",
      "1.3      1\n",
      "1.5      1\n",
      "        ..\n",
      "9.6     59\n",
      "9.7     20\n",
      "9.8     14\n",
      "9.9     18\n",
      "10.0     1\n",
      "Name: count, Length: 88, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploring our variable ranges and unique values\n",
    "\n",
    "# Categorical variables\n",
    "print(\"=== CATEGORICAL VARIABLES ===\")\n",
    "for col in ['batch', 'gender', 'age', 'qual_reasons']:\n",
    "    if col in data.columns:\n",
    "        print(f\"{col}: {data[col].nunique()} unique values\")\n",
    "        print(f\"Values: {data[col].unique()}\")\n",
    "        print()\n",
    "\n",
    "# Personality variables (pers_)\n",
    "print(\"=== PERSONALITY VARIABLES ===\")\n",
    "pers_cols = [col for col in data.columns if col.startswith('pers_')]\n",
    "for col in pers_cols:\n",
    "    unique_vals = sorted(data[col].unique())\n",
    "    print(f\"{col}: {min(unique_vals)}-{max(unique_vals)}, values: {unique_vals}\")\n",
    "\n",
    "# Likert variables (eml_, wfl_)\n",
    "print(\"\\n=== LIKERT VARIABLES ===\")\n",
    "likert_cols = [col for col in data.columns if col.startswith(('el_', 'wfl_'))]\n",
    "for col in likert_cols:\n",
    "    unique_vals = sorted(data[col].dropna().unique())\n",
    "    print(f\"{col}: {min(unique_vals)}-{max(unique_vals)}, values: {unique_vals}\")\n",
    "\n",
    "# Factor variables (emt_, wfs_)\n",
    "print(\"\\n=== FACTOR VARIABLES ===\")\n",
    "factor_cols = [col for col in data.columns if col.startswith(('es_', 'wfs_'))]\n",
    "for col in factor_cols:\n",
    "    non_null = data[col].dropna()\n",
    "    if len(non_null) > 0:\n",
    "        print(f\"{col}: range {non_null.min():.3f} to {non_null.max():.3f}, {non_null.nunique()} unique values\")\n",
    "\n",
    "# Prep level\n",
    "print(\"\\n=== PREP LEVEL ===\")\n",
    "prep_vals = sorted(data['prep_level'].dropna().unique())\n",
    "print(f\"prep_level: {min(prep_vals)} to {max(prep_vals)}\")\n",
    "print(f\"Values: {prep_vals}\")\n",
    "print(data['prep_level'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c7cab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above, we can appropriately set our data types\n",
    "# Convert categorical variables to category dtype\n",
    "data['batch'] = data['batch'].astype('category')\n",
    "data['gender'] = data['gender'].astype('category') \n",
    "data['qual_reasons'] = data['qual_reasons'].astype('object') # Keep qualitative as a string\n",
    "\n",
    "# Age as ordered categorical\n",
    "age_dtype = pd.CategoricalDtype(categories=['18-24', '25-40', '41-64'], ordered=True)\n",
    "data['age'] = data['age'].astype(age_dtype)\n",
    "\n",
    "\n",
    "# Personality variables (1-7 scale) - ordered categorical, great for ordinal survey responses\n",
    "pers_dtype = pd.CategoricalDtype(categories=[1,2,3,4,5,6,7], ordered=True)\n",
    "pers_cols = [col for col in data.columns if col.startswith('pers_')]\n",
    "for col in pers_cols:\n",
    "    data[col] = data[col].astype(pers_dtype)\n",
    "\n",
    "# EML Likert variables (-100 to 100, steps of 25) - ordered categorical  \n",
    "eml_dtype = pd.CategoricalDtype(categories=[-100,-75,-50,-25,0,25,50,75,100], ordered=True)\n",
    "eml_cols = [col for col in data.columns if col.startswith('eml_')]\n",
    "for col in eml_cols:\n",
    "    data[col] = data[col].astype(eml_dtype)\n",
    "\n",
    "# WFL Likert variables (0 to 100, steps of 25) - ordered categorical\n",
    "wfl_dtype = pd.CategoricalDtype(categories=[0,25,50,75,100], ordered=True)\n",
    "wfl_cols = [col for col in data.columns if col.startswith('wfl_')]\n",
    "for col in wfl_cols:\n",
    "    data[col] = data[col].astype(wfl_dtype)\n",
    "\n",
    "# Factor variables - keep as float32 (continuous scores, need decimal precision)\n",
    "emt_cols = [col for col in data.columns if col.startswith('emt_')]\n",
    "for col in emt_cols:\n",
    "    data[col] = data[col].astype('float32')\n",
    "\n",
    "wfs_cols = [col for col in data.columns if col.startswith('wfs_')]\n",
    "for col in wfs_cols:\n",
    "    data[col] = data[col].astype('float32')\n",
    "\n",
    "# Prep level - keep as float32 (has decimal values)\n",
    "data['prep_level'] = data['prep_level'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c470a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4211 entries, 0 to 4210\n",
      "Data columns (total 67 columns):\n",
      " #   Column                                Non-Null Count  Dtype   \n",
      "---  ------                                --------------  -----   \n",
      " 0   batch                                 4211 non-null   category\n",
      " 1   gender                                4211 non-null   category\n",
      " 2   age                                   4211 non-null   category\n",
      " 3   pers_extraverted_enthusiastic         4211 non-null   category\n",
      " 4   pers_critical_quarrelsome             4211 non-null   category\n",
      " 5   pers_dependable_self-disciplined      4211 non-null   category\n",
      " 6   pers_anxious_easily_upset             4211 non-null   category\n",
      " 7   pers_open_to_new_experiences_complex  4211 non-null   category\n",
      " 8   pers_sympathetic_warm                 4211 non-null   category\n",
      " 9   pers_disorganized_careless            4211 non-null   category\n",
      " 10  pers_reserved_quiet                   4211 non-null   category\n",
      " 11  pers_calm_emotionally_stable          4211 non-null   category\n",
      " 12  pers_conventional_uncreative          4211 non-null   category\n",
      " 13  prep_level                            4211 non-null   float32 \n",
      " 14  qual_reasons                          4189 non-null   object  \n",
      " 15  el_lbal_anx                           4211 non-null   int64   \n",
      " 16  el_lbal_sat                           4211 non-null   int64   \n",
      " 17  el_lcnt_com                           4211 non-null   int64   \n",
      " 18  el_lcnt_psy                           4211 non-null   int64   \n",
      " 19  el_lcon_inc                           4211 non-null   int64   \n",
      " 20  el_lcon_soc                           4211 non-null   int64   \n",
      " 21  el_lcont_con                          4211 non-null   int64   \n",
      " 22  el_lcont_imp                          4211 non-null   int64   \n",
      " 23  el_lgen                               4211 non-null   int64   \n",
      " 24  el_ljou_opt                           4211 non-null   int64   \n",
      " 25  el_ljou_pro                           4211 non-null   int64   \n",
      " 26  el_lres_fin                           4211 non-null   int64   \n",
      " 27  el_lres_ski                           4211 non-null   int64   \n",
      " 28  el_ltra_aut                           4211 non-null   int64   \n",
      " 29  el_ltra_des                           4211 non-null   int64   \n",
      " 30  wfl_lcarprom_d                        4211 non-null   category\n",
      " 31  wfl_lcollea                           4211 non-null   category\n",
      " 32  wfl_lenjhyb                           4211 non-null   category\n",
      " 33  wfl_lexcess_wk                        4210 non-null   category\n",
      " 34  wfl_lfin_lair                         4210 non-null   category\n",
      " 35  wfl_llearn_dev                        4211 non-null   category\n",
      " 36  wfl_lmean_full                        4210 non-null   category\n",
      " 37  wfl_lpoorman                          4211 non-null   category\n",
      " 38  wfl_ltoxic                            4211 non-null   category\n",
      " 39  wfl_luse_skills                       4210 non-null   category\n",
      " 40  wfl_lwellcomp                         4211 non-null   category\n",
      " 41  es_fbal_anx                           4210 non-null   float64 \n",
      " 42  es_fbal_sat                           4211 non-null   float64 \n",
      " 43  es_fcnt_com                           4211 non-null   float64 \n",
      " 44  es_fcnt_psy                           4211 non-null   float64 \n",
      " 45  es_fcon_inc                           4211 non-null   float64 \n",
      " 46  es_fcon_soc                           4209 non-null   float64 \n",
      " 47  es_fcont_con                          4210 non-null   float64 \n",
      " 48  es_fcont_imp                          4210 non-null   float64 \n",
      " 49  es_fgen                               4210 non-null   float64 \n",
      " 50  es_fjou_opt                           4211 non-null   float64 \n",
      " 51  es_fjou_pro                           4209 non-null   float64 \n",
      " 52  es_fres_fin                           4206 non-null   float64 \n",
      " 53  es_fres_ski                           4211 non-null   float64 \n",
      " 54  es_ftra_aut                           4211 non-null   float64 \n",
      " 55  es_ftra_des                           4210 non-null   float64 \n",
      " 56  wfs_fcarprom                          4210 non-null   float32 \n",
      " 57  wfs_fcollea                           4211 non-null   float32 \n",
      " 58  wfs_fenjhyb                           4211 non-null   float32 \n",
      " 59  wfs_fexcess_wk                        4211 non-null   float32 \n",
      " 60  wfs_ffin_fair                         4211 non-null   float32 \n",
      " 61  wfs_flearn_dev                        4211 non-null   float32 \n",
      " 62  wfs_fmean_full                        4211 non-null   float32 \n",
      " 63  wfs_fpoorman                          4211 non-null   float32 \n",
      " 64  wfs_ftoxic                            4208 non-null   float32 \n",
      " 65  wfs_fuse_skills                       4209 non-null   float32 \n",
      " 66  wfs_fwellcomp                         4211 non-null   float32 \n",
      "dtypes: category(24), float32(12), float64(15), int64(15), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54964da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     Je suis prête à m’engager, organise\n",
      "1       Jeune diplôme je suis prête à entrer dans le m...\n",
      "2       La nouvelle technologie, les nouveaux moyens m...\n",
      "3       Je suis prete à passer a une nouvelle étape de...\n",
      "4       Sa fait 4ans  que je suis en poste de chef d'é...\n",
      "                              ...                        \n",
      "4206    I am willing and ready for the next set of que...\n",
      "4207                                         Cody Reasons\n",
      "4208                                      Italian reasons\n",
      "4209                                           El Reasons\n",
      "4210                                      Reasons Spanish\n",
      "Name: qual_reasons, Length: 4211, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Little bit worried about the encoding of qualitative responses, since there's so many languages and unique characters\n",
    "print(data.loc[:,'qual_reasons'])\n",
    "\n",
    "# Should bear this in mind for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8a278ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sector</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pers_extraverted_enthusiastic</th>\n",
       "      <th>pers_critical_quarrelsome</th>\n",
       "      <th>pers_dependable_self-disciplined</th>\n",
       "      <th>pers_anxious_easily_upset</th>\n",
       "      <th>pers_open_to_new_experiences_complex</th>\n",
       "      <th>pers_sympathetic_warm</th>\n",
       "      <th>...</th>\n",
       "      <th>wfs_fcollea</th>\n",
       "      <th>wfs_fenjhyb</th>\n",
       "      <th>wfs_fexcess_wk</th>\n",
       "      <th>wfs_ffin_fair</th>\n",
       "      <th>wfs_flearn_dev</th>\n",
       "      <th>wfs_fmean_full</th>\n",
       "      <th>wfs_fpoorman</th>\n",
       "      <th>wfs_ftoxic</th>\n",
       "      <th>wfs_fuse_skills</th>\n",
       "      <th>wfs_fwellcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.555555</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>44.444443</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>63.333332</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>97.777779</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>37.777779</td>\n",
       "      <td>57.777779</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>92.222221</td>\n",
       "      <td>67.777779</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>16.666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>56.666668</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>72.222221</td>\n",
       "      <td>83.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>62.222221</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>27.777779</td>\n",
       "      <td>96.666664</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>22.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>91.111115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>84.444443</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.555557</td>\n",
       "      <td>98.888885</td>\n",
       "      <td>83.333336</td>\n",
       "      <td>58.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country sector  gender    age pers_extraverted_enthusiastic  \\\n",
       "0      FR   Tech  Female  18-24                             5   \n",
       "1      FR   Tech  Female  18-24                             5   \n",
       "2      FR   Tech  Female  18-24                             2   \n",
       "3      FR   Tech  Female  25-40                             4   \n",
       "4      FR   Tech  Female  25-40                             7   \n",
       "\n",
       "  pers_critical_quarrelsome pers_dependable_self-disciplined  \\\n",
       "0                         1                                7   \n",
       "1                         2                                6   \n",
       "2                         3                                1   \n",
       "3                         6                                1   \n",
       "4                         5                                7   \n",
       "\n",
       "  pers_anxious_easily_upset pers_open_to_new_experiences_complex  \\\n",
       "0                         3                                    7   \n",
       "1                         3                                    7   \n",
       "2                         4                                    2   \n",
       "3                         3                                    4   \n",
       "4                         5                                    7   \n",
       "\n",
       "  pers_sympathetic_warm  ... wfs_fcollea wfs_fenjhyb wfs_fexcess_wk  \\\n",
       "0                     7  ...   15.555555   65.555557      25.555555   \n",
       "1                     7  ...   48.888889   37.777779      57.777779   \n",
       "2                     2  ...   86.666664   60.000000      56.666668   \n",
       "3                     1  ...   25.555555   62.222221      40.000000   \n",
       "4                     7  ...   91.111115    0.000000      93.333336   \n",
       "\n",
       "  wfs_ffin_fair  wfs_flearn_dev wfs_fmean_full  wfs_fpoorman  wfs_ftoxic  \\\n",
       "0     44.444443       86.666664      63.333332     20.000000   97.777779   \n",
       "1     65.555557       76.666664      77.777779     92.222221   67.777779   \n",
       "2     48.888889       76.666664      91.666664     30.000000   38.888889   \n",
       "3     27.777779       96.666664      21.111111     70.000000   20.000000   \n",
       "4     90.000000       84.444443      70.000000     75.555557   98.888885   \n",
       "\n",
       "   wfs_fuse_skills  wfs_fwellcomp  \n",
       "0        91.666664     100.000000  \n",
       "1        93.333336      16.666666  \n",
       "2        72.222221      83.333336  \n",
       "3        93.333336      22.777779  \n",
       "4        83.333336      58.888889  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split batch group column between country and sector by space delimiter\n",
    "data[['country', 'sector']] = data['batch'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# Drop the original batch column\n",
    "data.drop(columns=['batch'], inplace=True)\n",
    "\n",
    "# set the new columns as first two columns\n",
    "data = data[['country', 'sector'] + [col for col in data.columns if col not in ['country', 'sector']]]\n",
    "\n",
    "# remove index column if it exists\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99838dba",
   "metadata": {},
   "source": [
    "Now we've got our data cleaned and formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ede7908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sector</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pers_extraverted_enthusiastic</th>\n",
       "      <th>pers_critical_quarrelsome</th>\n",
       "      <th>pers_dependable_self-disciplined</th>\n",
       "      <th>pers_anxious_easily_upset</th>\n",
       "      <th>pers_open_to_new_experiences_complex</th>\n",
       "      <th>pers_sympathetic_warm</th>\n",
       "      <th>...</th>\n",
       "      <th>wfs_fcollea</th>\n",
       "      <th>wfs_fenjhyb</th>\n",
       "      <th>wfs_fexcess_wk</th>\n",
       "      <th>wfs_ffin_fair</th>\n",
       "      <th>wfs_flearn_dev</th>\n",
       "      <th>wfs_fmean_full</th>\n",
       "      <th>wfs_fpoorman</th>\n",
       "      <th>wfs_ftoxic</th>\n",
       "      <th>wfs_fuse_skills</th>\n",
       "      <th>wfs_fwellcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.555555</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>44.444443</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>63.333332</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>97.777779</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>37.777779</td>\n",
       "      <td>57.777779</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>92.222221</td>\n",
       "      <td>67.777779</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>16.666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>56.666668</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>72.222221</td>\n",
       "      <td>83.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>62.222221</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>27.777779</td>\n",
       "      <td>96.666664</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>22.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>91.111115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>84.444443</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.555557</td>\n",
       "      <td>98.888885</td>\n",
       "      <td>83.333336</td>\n",
       "      <td>58.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country sector  gender    age pers_extraverted_enthusiastic  \\\n",
       "0      FR   Tech  Female  18-24                             5   \n",
       "1      FR   Tech  Female  18-24                             5   \n",
       "2      FR   Tech  Female  18-24                             2   \n",
       "3      FR   Tech  Female  25-40                             4   \n",
       "4      FR   Tech  Female  25-40                             7   \n",
       "\n",
       "  pers_critical_quarrelsome pers_dependable_self-disciplined  \\\n",
       "0                         1                                7   \n",
       "1                         2                                6   \n",
       "2                         3                                1   \n",
       "3                         6                                1   \n",
       "4                         5                                7   \n",
       "\n",
       "  pers_anxious_easily_upset pers_open_to_new_experiences_complex  \\\n",
       "0                         3                                    7   \n",
       "1                         3                                    7   \n",
       "2                         4                                    2   \n",
       "3                         3                                    4   \n",
       "4                         5                                    7   \n",
       "\n",
       "  pers_sympathetic_warm  ... wfs_fcollea wfs_fenjhyb wfs_fexcess_wk  \\\n",
       "0                     7  ...   15.555555   65.555557      25.555555   \n",
       "1                     7  ...   48.888889   37.777779      57.777779   \n",
       "2                     2  ...   86.666664   60.000000      56.666668   \n",
       "3                     1  ...   25.555555   62.222221      40.000000   \n",
       "4                     7  ...   91.111115    0.000000      93.333336   \n",
       "\n",
       "  wfs_ffin_fair  wfs_flearn_dev wfs_fmean_full  wfs_fpoorman  wfs_ftoxic  \\\n",
       "0     44.444443       86.666664      63.333332     20.000000   97.777779   \n",
       "1     65.555557       76.666664      77.777779     92.222221   67.777779   \n",
       "2     48.888889       76.666664      91.666664     30.000000   38.888889   \n",
       "3     27.777779       96.666664      21.111111     70.000000   20.000000   \n",
       "4     90.000000       84.444443      70.000000     75.555557   98.888885   \n",
       "\n",
       "   wfs_fuse_skills  wfs_fwellcomp  \n",
       "0        91.666664     100.000000  \n",
       "1        93.333336      16.666666  \n",
       "2        72.222221      83.333336  \n",
       "3        93.333336      22.777779  \n",
       "4        83.333336      58.888889  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db24f52",
   "metadata": {},
   "source": [
    "Let's also check for missing values and any unique encoding schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "324fa30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECKING FOR MISSING VALUE INDICATORS ===\n",
      "\n",
      "country:\n",
      "  OK\n",
      "sector:\n",
      "  OK\n",
      "gender:\n",
      "  OK\n",
      "age:\n",
      "  OK\n",
      "pers_extraverted_enthusiastic:\n",
      "  OK\n",
      "pers_critical_quarrelsome:\n",
      "  OK\n",
      "pers_dependable_self-disciplined:\n",
      "  OK\n",
      "pers_anxious_easily_upset:\n",
      "  OK\n",
      "pers_open_to_new_experiences_complex:\n",
      "  OK\n",
      "pers_sympathetic_warm:\n",
      "  OK\n",
      "pers_disorganized_careless:\n",
      "  OK\n",
      "pers_reserved_quiet:\n",
      "  OK\n",
      "pers_calm_emotionally_stable:\n",
      "  OK\n",
      "pers_conventional_uncreative:\n",
      "  OK\n",
      "prep_level:\n",
      "  OK (88 unique values)\n",
      "qual_reasons:\n",
      "  SUSPICIOUS: ['-']\n",
      "el_lbal_anx:\n",
      "  OK\n",
      "el_lbal_sat:\n",
      "  OK\n",
      "el_lcnt_com:\n",
      "  OK\n",
      "el_lcnt_psy:\n",
      "  OK\n",
      "el_lcon_inc:\n",
      "  OK\n",
      "el_lcon_soc:\n",
      "  OK\n",
      "el_lcont_con:\n",
      "  OK\n",
      "el_lcont_imp:\n",
      "  OK\n",
      "el_lgen:\n",
      "  OK\n",
      "el_ljou_opt:\n",
      "  OK\n",
      "el_ljou_pro:\n",
      "  OK\n",
      "el_lres_fin:\n",
      "  OK\n",
      "el_lres_ski:\n",
      "  OK\n",
      "el_ltra_aut:\n",
      "  OK\n",
      "el_ltra_des:\n",
      "  OK\n",
      "wfl_lcarprom_d:\n",
      "  OK\n",
      "wfl_lcollea:\n",
      "  OK\n",
      "wfl_lenjhyb:\n",
      "  OK\n",
      "wfl_lexcess_wk:\n",
      "  OK\n",
      "wfl_lfin_lair:\n",
      "  OK\n",
      "wfl_llearn_dev:\n",
      "  OK\n",
      "wfl_lmean_full:\n",
      "  OK\n",
      "wfl_lpoorman:\n",
      "  OK\n",
      "wfl_ltoxic:\n",
      "  OK\n",
      "wfl_luse_skills:\n",
      "  OK\n",
      "wfl_lwellcomp:\n",
      "  OK\n",
      "es_fbal_anx:\n",
      "  OK (513 unique values)\n",
      "es_fbal_sat:\n",
      "  OK (541 unique values)\n",
      "es_fcnt_com:\n",
      "  OK (547 unique values)\n",
      "es_fcnt_psy:\n",
      "  OK (530 unique values)\n",
      "es_fcon_inc:\n",
      "  OK (544 unique values)\n",
      "es_fcon_soc:\n",
      "  OK (508 unique values)\n",
      "es_fcont_con:\n",
      "  OK (511 unique values)\n",
      "es_fcont_imp:\n",
      "  OK (506 unique values)\n",
      "es_fgen:\n",
      "  OK (500 unique values)\n",
      "es_fjou_opt:\n",
      "  OK (549 unique values)\n",
      "es_fjou_pro:\n",
      "  OK (522 unique values)\n",
      "es_fres_fin:\n",
      "  OK (522 unique values)\n",
      "es_fres_ski:\n",
      "  OK (508 unique values)\n",
      "es_ftra_aut:\n",
      "  OK (520 unique values)\n",
      "es_ftra_des:\n",
      "  OK (514 unique values)\n",
      "wfs_fcarprom:\n",
      "  OK (178 unique values)\n",
      "wfs_fcollea:\n",
      "  OK (187 unique values)\n",
      "wfs_fenjhyb:\n",
      "  OK (189 unique values)\n",
      "wfs_fexcess_wk:\n",
      "  OK (185 unique values)\n",
      "wfs_ffin_fair:\n",
      "  OK (184 unique values)\n",
      "wfs_flearn_dev:\n",
      "  OK (174 unique values)\n",
      "wfs_fmean_full:\n",
      "  OK (180 unique values)\n",
      "wfs_fpoorman:\n",
      "  OK (189 unique values)\n",
      "wfs_ftoxic:\n",
      "  OK (186 unique values)\n",
      "wfs_fuse_skills:\n",
      "  OK (174 unique values)\n",
      "wfs_fwellcomp:\n",
      "  OK (183 unique values)\n",
      "\n",
      "=== MISSING DATA SUMMARY ===\n",
      "qual_reasons       22\n",
      "wfl_lexcess_wk      1\n",
      "wfl_lfin_lair       1\n",
      "wfl_lmean_full      1\n",
      "wfl_luse_skills     1\n",
      "es_fbal_anx         1\n",
      "es_fcon_soc         2\n",
      "es_fcont_con        1\n",
      "es_fcont_imp        1\n",
      "es_fgen             1\n",
      "es_fjou_pro         2\n",
      "es_fres_fin         5\n",
      "es_ftra_des         1\n",
      "wfs_fcarprom        1\n",
      "wfs_ftoxic          3\n",
      "wfs_fuse_skills     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values and recode any non-response indicators as NA\n",
    "\n",
    "# Check for common missing value indicators\n",
    "missing_indicators = ['', ' ', 'NA', 'N/A', 'null', 'NULL', 'None', 'NONE', \n",
    "                     'missing', 'Missing', 'MISSING', '?', '-', '--', \n",
    "                     '999', '-999', '9999', '-9999', '99', '-99']\n",
    "\n",
    "print(\"=== CHECKING FOR MISSING VALUE INDICATORS ===\\n\")\n",
    "\n",
    "# Check each column for potential missing indicators\n",
    "for col in data.columns:\n",
    "    print(f\"{col}:\")\n",
    "    \n",
    "    # Get unique values (first 10 and last 10 if many)\n",
    "    unique_vals = data[col].unique()\n",
    "    \n",
    "    if len(unique_vals) <= 20:\n",
    "        suspicious = [val for val in unique_vals if str(val) in missing_indicators]\n",
    "        if suspicious:\n",
    "            print(f\"  SUSPICIOUS: {suspicious}\")\n",
    "        else:\n",
    "            print(f\"  OK\")\n",
    "    else:\n",
    "        # For columns with many unique values, just check if any missing indicators present\n",
    "        suspicious = [val for val in unique_vals if str(val) in missing_indicators]\n",
    "        if suspicious:\n",
    "            print(f\"  SUSPICIOUS: {suspicious}\")\n",
    "        else:\n",
    "            print(f\"  OK ({len(unique_vals)} unique values)\")\n",
    "    \n",
    "    # Also check for unusual patterns in numeric columns\n",
    "    if data[col].dtype in ['int64', 'float64', 'int8', 'float32']:\n",
    "        numeric_vals = pd.to_numeric(data[col], errors='coerce')\n",
    "        \n",
    "        # Check for extreme values that might be missing indicators\n",
    "        if not numeric_vals.isna().all():\n",
    "            min_val, max_val = numeric_vals.min(), numeric_vals.max()\n",
    "            \n",
    "            # Flag if we see common missing codes\n",
    "            extreme_vals = numeric_vals[numeric_vals.isin([99, -99, 999, -999, 9999, -9999])]\n",
    "            if len(extreme_vals) > 0:\n",
    "                print(f\"  EXTREME VALUES: {extreme_vals.unique()}\")\n",
    "\n",
    "print(\"\\n=== MISSING DATA SUMMARY ===\")\n",
    "print(data.isnull().sum()[data.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e92fa",
   "metadata": {},
   "source": [
    "Finally let's save our data for further analysis. To preserve our data types, let's save as a pickle file, rather than csv. \n",
    "Also let's add an md file as our codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "49212435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle file\n",
    "data.to_pickle(\"../data/survey_data_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae529c",
   "metadata": {},
   "source": [
    "### Ongoing Questions\n",
    "\n",
    "- Not understanding the fast choice responses? Why are some negative? What does it substantively represent? Not understanding the ranges at the moment\n",
    "- Fast choice are implicit scores? Whereas likert are explicit scores? What does this signify?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
