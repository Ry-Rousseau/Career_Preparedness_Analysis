{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24957d71",
   "metadata": {},
   "source": [
    "#### Step 1: Item Reduction\n",
    "\n",
    "Which survey items are actually measuring distinct, meaningful constructs vs. which ones are redundant, unclear or not contributing much?\n",
    "\n",
    "We want to keep the questions that clearly measure different underlying social constructs. We should do this for both the implicit and the explicit variables, as we hypothesize that both are driven by similar underlying psychological profiles.\n",
    "\n",
    "Does our data require item reduction? Should we perform any theoretical selection? Filtering before our factor analysis.\n",
    "\n",
    "We might firstly check the Kaiser-Meyer-Olkin (KMR) measure of sampling adequacy. This is essentially of measure of how correlated our variables are. We are looking for a high value close to 1 which indicates high correlation between related variables, but not too much multicollinearity, and an effective sample size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMO Analysis\n",
    "import pandas as pd\n",
    "from factor_analyzer import calculate_kmo\n",
    "\n",
    "data = pd.read_pickle(\"../data/survey_data_cleaned.pkl\")\n",
    "\n",
    "def get_kmo(variables, name):\n",
    "    df_clean = data[variables].dropna()\n",
    "    kmo_all, kmo_model = calculate_kmo(df_clean.values.astype(float))\n",
    "    print(f\"{name}: KMO = {kmo_model:.3f}\")\n",
    "    return kmo_model\n",
    "\n",
    "# Variable groups\n",
    "emotional_vars = [col for col in data.columns if col.startswith(('es_', 'el_'))]\n",
    "workplace_vars = [col for col in data.columns if col.startswith(('wfs_', 'wfl_'))]\n",
    "latent_vars = [col for col in data.columns if col.startswith(('es_', 'wfs_'))]\n",
    "explicit_vars = [col for col in data.columns if col.startswith(('el_', 'wfl_'))]\n",
    "\n",
    "# Calculate KMO\n",
    "print(\"KMO Results:\")\n",
    "get_kmo(emotional_vars, \"Emotional\")\n",
    "get_kmo(workplace_vars, \"Workplace\") \n",
    "get_kmo(latent_vars, \"Latent (Fast Choice)\")\n",
    "get_kmo(explicit_vars, \"Explicit (Likert)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c91cd",
   "metadata": {},
   "source": [
    "Given these fairly excellent KMO results, we don't want to reduce our items at all, as this may reduce meaningful information provide by our excellent survey results. Hence, we're ready for factor analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a442a9",
   "metadata": {},
   "source": [
    "#### Step 2: Extraction of Factors\n",
    "\n",
    "Here we'll select factor variables, standardize our data, apply kaiser criterion, create scree plots and extract final factors.\n",
    "\n",
    "But firstly, we should just look at what the data can tell us. \n",
    "\n",
    "Let's look at the correlation matrix for our two categories of responses: fast-choice and likert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0ae3f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 61\u001b[0m\n\u001b[0;32m     35\u001b[0m workplace_names \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfs_fuse_skills\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m◆ Can use skills\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfs_flearn_dev\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m◆ Learning opportunities\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfl_lenjhyb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m◆ Enjoy hybrid working (L)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     58\u001b[0m }\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Get variable lists\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m fast_choice_vars \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfs_\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     62\u001b[0m likert_vars \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mel_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwfl_\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate correlations\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Create informative variable name mappings from codebook with symbols\n",
    "emotional_names = {\n",
    "    'es_fgen': '* Ready for next step',\n",
    "    'es_ftra_des': '* Want new start', \n",
    "    'es_ftra_aut': '* Freedom to change',\n",
    "    'es_fcnt_com': '* Comfortable where I am',\n",
    "    'es_fcnt_psy': '* Voice is heard',\n",
    "    'es_fcon_soc': '* Others influence decisions',\n",
    "    'es_fbal_anx': '* Anxious about change',\n",
    "    'es_fres_fin': '* Financially motivated',\n",
    "    'es_fcont_imp': '* Believe in myself',\n",
    "    'es_fjou_opt': '* Optimistic about future',\n",
    "    'es_fcon_inc': '* Feel included',\n",
    "    'es_fbal_sat': '* Happy where I am',\n",
    "    'es_fres_ski': '* Skills to progress',\n",
    "    'es_fcont_con': '* Control next step',\n",
    "    'es_fjou_pro': '* Set myself goals',\n",
    "    'el_lgen': '* Ready for next step (L)',\n",
    "    'el_ltra_des': '* Want new start (L)',\n",
    "    'el_ltra_aut': '* Freedom to change (L)', \n",
    "    'el_lcnt_com': '* Comfortable where I am (L)',\n",
    "    'el_lcnt_psy': '* Voice is heard (L)',\n",
    "    'el_lcon_soc': '* Others influence decisions (L)',\n",
    "    'el_lbal_anx': '* Anxious about change (L)',\n",
    "    'el_lres_fin': '* Financially motivated (L)',\n",
    "    'el_lcont_imp': '* Believe in myself (L)',\n",
    "    'el_ljou_opt': '* Optimistic about future (L)',\n",
    "    'el_lcon_inc': '* Feel included (L)',\n",
    "    'el_lbal_sat': '* Happy where I am (L)',\n",
    "    'el_lres_ski': '* Skills to progress (L)',\n",
    "    'el_lcont_con': '* Control next step (L)',\n",
    "    'el_ljou_pro': '* Set myself goals (L)'\n",
    "}\n",
    "\n",
    "workplace_names = {\n",
    "    'wfs_fuse_skills': '◆ Can use skills',\n",
    "    'wfs_flearn_dev': '◆ Learning opportunities',\n",
    "    'wfs_fcarprom': '◆ Can grow here',\n",
    "    'wfs_fmean_full': '◆ Job meaningful',\n",
    "    'wfs_fpoorman': '◆ Manager is poor',\n",
    "    'wfs_ftoxic': '◆ Culture is toxic',\n",
    "    'wfs_fexcess_wk': '◆ Working too hard',\n",
    "    'wfs_fcollea': '◆ Don\\'t get along with colleagues',\n",
    "    'wfs_fwellcomp': '◆ Well compensated',\n",
    "    'wfs_ffin_fair': '◆ Salary unfair vs colleagues',\n",
    "    'wfs_fenjhyb': '◆ Enjoy hybrid working',\n",
    "    'wfl_luse_skills': '◆ Can use skills (L)',\n",
    "    'wfl_llearn_dev': '◆ Learning opportunities (L)',\n",
    "    'wfl_lcarprom_d': '◆ Can grow here (L)',\n",
    "    'wfl_lmean_full': '◆ Job meaningful (L)',\n",
    "    'wfl_lpoorman': '◆ Manager is poor (L)',\n",
    "    'wfl_ltoxic': '◆ Culture is toxic (L)',\n",
    "    'wfl_lexcess_wk': '◆ Working too hard (L)',\n",
    "    'wfl_lcollea': '◆ Don\\'t get along with colleagues (L)',\n",
    "    'wfl_lwellcomp': '◆ Well compensated (L)',\n",
    "    'wfl_lfin_lair': '◆ Salary unfair vs colleagues (L)',\n",
    "    'wfl_lenjhyb': '◆ Enjoy hybrid working (L)'\n",
    "}\n",
    "\n",
    "# Get variable lists\n",
    "fast_choice_vars = [col for col in data.columns if col.startswith(('es_', 'wfs_'))]\n",
    "likert_vars = [col for col in data.columns if col.startswith(('el_', 'wfl_'))]\n",
    "\n",
    "# Calculate correlations\n",
    "fast_choice_corr = data[fast_choice_vars].corr()\n",
    "likert_corr = data[likert_vars].corr()\n",
    "\n",
    "# Create combined name mapping\n",
    "all_names = {**emotional_names, **workplace_names}\n",
    "\n",
    "# Rename correlation matrix indices and columns\n",
    "fast_choice_corr_renamed = fast_choice_corr.rename(index=all_names, columns=all_names)\n",
    "likert_corr_renamed = likert_corr.rename(index=all_names, columns=all_names)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create color coding for variable types\n",
    "def add_variable_type_colors(ax, var_names, var_list):\n",
    "    \"\"\"Add colored bars to distinguish emotional vs workplace variables\"\"\"\n",
    "    colors = []\n",
    "    for var in var_list:\n",
    "        if var.startswith(('es_', 'el_')):\n",
    "            colors.append('#FF6B6B')  # Red for emotional\n",
    "        else:\n",
    "            colors.append('#4ECDC4')  # Teal for workplace\n",
    "    \n",
    "    # Add colored bar on left side\n",
    "    for i, color in enumerate(colors):\n",
    "        ax.add_patch(plt.Rectangle((-0.1, i), 0.1, 1, color=color, clip_on=False))\n",
    "    \n",
    "    # Add colored bar on bottom\n",
    "    for i, color in enumerate(colors):\n",
    "        ax.add_patch(plt.Rectangle((i, -0.1), 1, 0.1, color=color, clip_on=False))\n",
    "\n",
    "# Fast choice correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.heatmap(fast_choice_corr_renamed, annot=False, cmap=\"coolwarm\", square=True, \n",
    "           cbar_kws={\"shrink\": .8}, vmin=-1, vmax=1, ax=ax)\n",
    "ax.set_title(\"Fast Choice Variables Correlation Matrix\", fontsize=16, pad=20)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='*', color='w', markerfacecolor='black', \n",
    "                             markersize=10, label='* Emotional Variables'),\n",
    "                  plt.Line2D([0], [0], marker='D', color='w', markerfacecolor='black', \n",
    "                            markersize=8, label='◆ Workplace Variables')]\n",
    "ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Likert correlation matrix  \n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.heatmap(likert_corr_renamed, annot=False, cmap=\"coolwarm\", square=True,\n",
    "           cbar_kws={\"shrink\": .8}, vmin=-1, vmax=1, ax=ax)\n",
    "ax.set_title(\"Likert Variables Correlation Matrix\", fontsize=16, pad=20)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='*', color='w', markerfacecolor='black', \n",
    "                             markersize=10, label='* Emotional Variables'),\n",
    "                  plt.Line2D([0], [0], marker='D', color='w', markerfacecolor='black', \n",
    "                            markersize=8, label='◆ Workplace Variables')]\n",
    "ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2a1bb",
   "metadata": {},
   "source": [
    "Immediately we can see some very clear patterns.\n",
    "\n",
    "Fast Choice Vars:\n",
    "- Correlations are not as strong comparatively\n",
    "- Covariance among subset of emotional variables, specifically those related to believing in one's self and future planning\n",
    "- Some very logical correlations, between 'can grow here' and 'learning opportunities/job meaningful'\n",
    "- Some clear groupings, it would make sense that there's latent factors explaining our variance\n",
    "- Emotional vars tend to co-vary, as do Workplace/Functional, but covariance between the two is less common \n",
    "\n",
    "Likert Variables:\n",
    "- Stronger correlations in general, especially within the emotional/workplace groupings\n",
    "- A lot less gray, implies that likert responses are just more extreme (i.e. perhaps people are more decisive when they have time to think about their answers)\n",
    "\n",
    "Interestingly, in both, some questions just don't correlate much at all.\n",
    "\n",
    "What about correlations with \"Ready for next step\"\n",
    "\n",
    "Fast choice:\n",
    "- Positive: Believe in myself, In control of next step, freedom to change etc.\n",
    "- Negative: Anxious about change, others influence financial decisions, \n",
    "\n",
    "Likert:\n",
    "- Positive: Set myself goals, freedom to change, skills to progress, can use skills\n",
    "- Negative: Anxious about change, others influence decisions, don't get along with colleagues, salary unfair, manager poor/toxic \n",
    "\n",
    "We can really start to see why a factor analysis is beneficial for our data. There's a lot of variables and variance patterns to sort through. A manually encoding approach would probably introduce a lot of measurement error. Likewise, it's very plausible that our factor analysis would pick up a real 'latent factors'.\n",
    "\n",
    "##### Now let's proceed onto the factor analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39483b0c",
   "metadata": {},
   "source": [
    "Need to evaluate:\n",
    "1) factor loading - how high the correlation between the variable and the factor\n",
    "2) eigenvalue - how much variance can be explained by the factor of all variables\n",
    "3) communality - how much variance of the total variables can be explained by the factors \n",
    "\n",
    "To do the above, we need the communalities and the factor component matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import bartlett\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "\n",
    "# Variable name mappings from your code\n",
    "emotional_names = {\n",
    "    'es_fgen': '* Ready for next step',\n",
    "    'es_ftra_des': '* Want new start', \n",
    "    'es_ftra_aut': '* Freedom to change',\n",
    "    'es_fcnt_com': '* Comfortable where I am',\n",
    "    'es_fcnt_psy': '* Voice is heard',\n",
    "    'es_fcon_soc': '* Others influence decisions',\n",
    "    'es_fbal_anx': '* Anxious about change',\n",
    "    'es_fres_fin': '* Financially motivated',\n",
    "    'es_fcont_imp': '* Believe in myself',\n",
    "    'es_fjou_opt': '* Optimistic about future',\n",
    "    'es_fcon_inc': '* Feel included',\n",
    "    'es_fbal_sat': '* Happy where I am',\n",
    "    'es_fres_ski': '* Skills to progress',\n",
    "    'es_fcont_con': '* Control next step',\n",
    "    'es_fjou_pro': '* Set myself goals',\n",
    "    'el_lgen': '* Ready for next step (L)',\n",
    "    'el_ltra_des': '* Want new start (L)',\n",
    "    'el_ltra_aut': '* Freedom to change (L)', \n",
    "    'el_lcnt_com': '* Comfortable where I am (L)',\n",
    "    'el_lcnt_psy': '* Voice is heard (L)',\n",
    "    'el_lcon_soc': '* Others influence decisions (L)',\n",
    "    'el_lbal_anx': '* Anxious about change (L)',\n",
    "    'el_lres_fin': '* Financially motivated (L)',\n",
    "    'el_lcont_imp': '* Believe in myself (L)',\n",
    "    'el_ljou_opt': '* Optimistic about future (L)',\n",
    "    'el_lcon_inc': '* Feel included (L)',\n",
    "    'el_lbal_sat': '* Happy where I am (L)',\n",
    "    'el_lres_ski': '* Skills to progress (L)',\n",
    "    'el_lcont_con': '* Control next step (L)',\n",
    "    'el_ljou_pro': '* Set myself goals (L)'\n",
    "}\n",
    "\n",
    "workplace_names = {\n",
    "    'wfs_fuse_skills': '◆ Can use skills',\n",
    "    'wfs_flearn_dev': '◆ Learning opportunities',\n",
    "    'wfs_fcarprom': '◆ Can grow here',\n",
    "    'wfs_fmean_full': '◆ Job meaningful',\n",
    "    'wfs_fpoorman': '◆ Manager is poor',\n",
    "    'wfs_ftoxic': '◆ Culture is toxic',\n",
    "    'wfs_fexcess_wk': '◆ Working too hard',\n",
    "    'wfs_fcollea': '◆ Don\\'t get along with colleagues',\n",
    "    'wfs_fwellcomp': '◆ Well compensated',\n",
    "    'wfs_ffin_fair': '◆ Salary unfair vs colleagues',\n",
    "    'wfs_fenjhyb': '◆ Enjoy hybrid working',\n",
    "    'wfl_luse_skills': '◆ Can use skills (L)',\n",
    "    'wfl_llearn_dev': '◆ Learning opportunities (L)',\n",
    "    'wfl_lcarprom_d': '◆ Can grow here (L)',\n",
    "    'wfl_lmean_full': '◆ Job meaningful (L)',\n",
    "    'wfl_lpoorman': '◆ Manager is poor (L)',\n",
    "    'wfl_ltoxic': '◆ Culture is toxic (L)',\n",
    "    'wfl_lexcess_wk': '◆ Working too hard (L)',\n",
    "    'wfl_lcollea': '◆ Don\\'t get along with colleagues (L)',\n",
    "    'wfl_lwellcomp': '◆ Well compensated (L)',\n",
    "    'wfl_lfin_lair': '◆ Salary unfair vs colleagues (L)',\n",
    "    'wfl_lenjhyb': '◆ Enjoy hybrid working (L)'\n",
    "}\n",
    "\n",
    "# Combine mappings\n",
    "all_names = {**emotional_names, **workplace_names}\n",
    "\n",
    "# Get variable lists from your existing code\n",
    "fast_choice_vars = [col for col in data.columns if col.startswith(('es_', 'wfs_'))]\n",
    "likert_vars = [col for col in data.columns if col.startswith(('el_', 'wfl_'))]\n",
    "\n",
    "print(f\"Fast choice variables: {len(fast_choice_vars)}\")\n",
    "print(f\"Likert variables: {len(likert_vars)}\")\n",
    "\n",
    "def perform_factor_analysis(df, var_list, title_prefix):\n",
    "    \"\"\"Perform factor analysis with scree plot\"\"\"\n",
    "    \n",
    "    # Select and clean data\n",
    "    fa_data = df[var_list].dropna()\n",
    "    print(f\"\\n{title_prefix} - Sample size after removing missing: {len(fa_data)}\")\n",
    "    \n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "    fa_data_scaled = scaler.fit_transform(fa_data)\n",
    "    fa_data_scaled = pd.DataFrame(fa_data_scaled, columns=var_list)\n",
    "    \n",
    "    # Test assumptions\n",
    "    # Bartlett's test for sphericity\n",
    "    chi_square_value, p_value = calculate_bartlett_sphericity(fa_data_scaled)\n",
    "    print(f\"Bartlett's test: Chi-square = {chi_square_value:.2f}, p-value = {p_value:.4f}\")\n",
    "    \n",
    "    # Kaiser-Meyer-Olkin test\n",
    "    kmo_all, kmo_model = calculate_kmo(fa_data_scaled)\n",
    "    print(f\"KMO test: {kmo_model:.3f}\")\n",
    "    \n",
    "    # Scree plot - determine number of factors\n",
    "    fa_scree = FactorAnalyzer(n_factors=len(var_list), rotation=None)\n",
    "    fa_scree.fit(fa_data_scaled)\n",
    "    \n",
    "    # Get eigenvalues\n",
    "    eigenvalues, _ = fa_scree.get_eigenvalues()\n",
    "    \n",
    "    # Create scree plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    factors = range(1, len(eigenvalues) + 1)\n",
    "    plt.plot(factors, eigenvalues, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.axhline(y=1, color='r', linestyle='--', alpha=0.7, label='Kaiser criterion (eigenvalue = 1)')\n",
    "    plt.title(f'{title_prefix} - Scree Plot')\n",
    "    plt.xlabel('Factor Number')\n",
    "    plt.ylabel('Eigenvalue')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add eigenvalue labels\n",
    "    for i, ev in enumerate(eigenvalues[:10]):  # Label first 10\n",
    "        plt.annotate(f'{ev:.2f}', (i+1, ev), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Determine number of factors (Kaiser criterion: eigenvalue > 1)\n",
    "    n_factors = sum(eigenvalues > 1)\n",
    "    print(f\"Number of factors (Kaiser criterion): {n_factors}\")\n",
    "    \n",
    "    # Alternative: explained variance criterion (e.g., 60-70%)\n",
    "    cumvar = np.cumsum(eigenvalues) / sum(eigenvalues) * 100\n",
    "    n_factors_60 = sum(cumvar < 60) + 1\n",
    "    n_factors_70 = sum(cumvar < 70) + 1\n",
    "    \n",
    "    print(f\"Factors explaining 60% variance: {n_factors_60}\")\n",
    "    print(f\"Factors explaining 70% variance: {n_factors_70}\")\n",
    "    print(f\"First 5 factors explain: {cumvar[4]:.1f}% of variance\")\n",
    "    \n",
    "    # Perform factor analysis with determined number of factors\n",
    "    n_factors_final = max(2, min(n_factors, 5))  # Use 2-5 factors\n",
    "    print(f\"\\nUsing {n_factors_final} factors for analysis\")\n",
    "    \n",
    "    # Factor analysis with varimax rotation\n",
    "    fa = FactorAnalyzer(n_factors=n_factors_final, rotation='varimax')\n",
    "    fa.fit(fa_data_scaled)\n",
    "    \n",
    "    # Get results with proper variable names\n",
    "    loadings = pd.DataFrame(fa.loadings_, \n",
    "                           columns=[f'Factor{i+1}' for i in range(n_factors_final)],\n",
    "                           index=var_list)\n",
    "    \n",
    "    # Add descriptive names\n",
    "    loadings['Variable_Name'] = loadings.index.map(all_names)\n",
    "    loadings = loadings[['Variable_Name'] + [f'Factor{i+1}' for i in range(n_factors_final)]]\n",
    "    \n",
    "    communalities = pd.DataFrame({'Variable_Name': [all_names.get(var, var) for var in var_list],\n",
    "                                 'Communality': fa.get_communalities()}, \n",
    "                                index=var_list)\n",
    "    \n",
    "    eigenvalues_final = fa.get_eigenvalues()[0][:n_factors_final]\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n=== {title_prefix} RESULTS ===\")\n",
    "    print(f\"\\nEigenvalues and Variance Explained:\")\n",
    "    total_variance = sum(eigenvalues_final)\n",
    "    cumulative = 0\n",
    "    for i, ev in enumerate(eigenvalues_final):\n",
    "        var_explained = ev / len(var_list) * 100\n",
    "        prop_explained = ev / total_variance * 100\n",
    "        cumulative += prop_explained\n",
    "        print(f\"Factor {i+1}: {ev:.3f} | {var_explained:.1f}% of total | {prop_explained:.1f}% of extracted | {cumulative:.1f}% cumulative\")\n",
    "    \n",
    "    # Factor loadings heatmap\n",
    "    print(f\"\\nFactor Loadings Matrix:\")\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    loadings_heatmap = loadings.copy()\n",
    "    factor_cols = [f'Factor{i+1}' for i in range(n_factors_final)]\n",
    "    loadings_matrix = loadings_heatmap[factor_cols]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(8, max(6, len(var_list) * 0.3)))\n",
    "    \n",
    "    # Use RdBu_r colormap (red-white-blue reversed) for better positive/negative distinction\n",
    "    sns.heatmap(loadings_matrix, \n",
    "                annot=True, \n",
    "                fmt='.3f',\n",
    "                cmap='RdBu_r', \n",
    "                center=0,\n",
    "                vmin=-1, \n",
    "                vmax=1,\n",
    "                cbar_kws={'label': 'Factor Loading'},\n",
    "                yticklabels=[all_names.get(var, var) for var in var_list])\n",
    "    \n",
    "    plt.title(f'{title_prefix} - Factor Loadings Matrix')\n",
    "    plt.xlabel('Factors')\n",
    "    plt.ylabel('Variables')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Communalities table\n",
    "    print(f\"\\nCommunalities (sorted by value):\")\n",
    "    print(\"=\" * 50)\n",
    "    comm_sorted = communalities.sort_values('Communality', ascending=False)\n",
    "    print(f\"{'Variable':<35} {'Communality':>10}\")\n",
    "    print(\"-\" * 47)\n",
    "    for idx, row in comm_sorted.iterrows():\n",
    "        var_name = row['Variable_Name'][:33] + ('...' if len(row['Variable_Name']) > 33 else '')\n",
    "        comm_val = row['Communality']\n",
    "        print(f\"{var_name:<35} {comm_val:>8.3f}\")\n",
    "    \n",
    "    # Low communalities warning\n",
    "    low_comm = communalities[communalities['Communality'] < 0.3]\n",
    "    if len(low_comm) > 0:\n",
    "        print(f\"\\n⚠️  Variables with low communalities (< 0.3) - consider removal:\")\n",
    "        for idx, row in low_comm.iterrows():\n",
    "            print(f\"   {row['Variable_Name']}: {row['Communality']:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n✅ All variables have adequate communalities (≥ 0.3)\")\n",
    "    \n",
    "    return {\n",
    "        'loadings': loadings,\n",
    "        'communalities': communalities,\n",
    "        'eigenvalues': eigenvalues_final,\n",
    "        'factor_analyzer': fa,\n",
    "        'n_factors': n_factors_final\n",
    "    }\n",
    "\n",
    "# Perform factor analysis for both groups\n",
    "print(\"=\"*60)\n",
    "print(\"FACTOR ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fast choice variables\n",
    "results_fast = perform_factor_analysis(data, fast_choice_vars, \"Fast Choice Variables\")\n",
    "\n",
    "# Likert variables  \n",
    "results_likert = perform_factor_analysis(data, likert_vars, \"Likert Variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256282e",
   "metadata": {},
   "source": [
    "##### Interpreting the factors\n",
    "\n",
    "Factor 1: Appears to capture career agency/self-efficacy - high loadings on \"Ready for next step\" (0.687), \"Set myself goals\" (0.606), \"Control next step\" (0.572), \"Believe in myself\" (0.563)\n",
    "\n",
    "Factor 2: Looks like workplace satisfaction/growth - strong loadings on \"Can grow here\" (0.757), \"Job meaningful\" (0.711), \"Learning opportunities\" (0.675), \"Can use skills\" (0.650)\n",
    "\n",
    "Factor 3: Represents workplace dysfunction - high loadings on \"Culture is toxic\" (0.643), \"Manager is poor\" (0.681), \"Salary unfair vs colleagues\" (0.595)\n",
    "\n",
    "Factor 4: Mixed factor, harder to interpret cleanly (probably left-over variance, non correlated variables)\n",
    "\n",
    "Factor 5: Also mixed, potentially workplace comfort but weak loadings (probably left-over variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
