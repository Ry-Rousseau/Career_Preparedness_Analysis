{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1d77ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: missingno in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2024.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from missingno) (1.15.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (2.0.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastparquet) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rhrou\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn missingno plotly openpyxl pyarrow fastparquet\n",
    "\n",
    "# load all packages for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "\n",
    "# load the data\n",
    "data = pd.read_excel(\"../data/CDS_25_Task1.xlsx\", sheet_name='Data', header=1, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3dff3",
   "metadata": {},
   "source": [
    "### Emotional, workplace, and environmental factor codes\n",
    "| Group | Subgroup | Statement | Fast Choice Keys | Likert Keys |\n",
    "|-------|----------|-----------|------------------|-------------|\n",
    "| Emotional | General | I'm ready for my next step | Fgen | Lgen |\n",
    "| Emotional | Transformation | I want a new start | FTraDes | LTraDes |\n",
    "| Emotional | Transformation | I've got freedom to change | FTraAut | LTraAut |\n",
    "| Emotional | Containers | I'm comfortable where I am | FCntCom | LCntCom |\n",
    "| Emotional | Containers | I feel like my voice is heard | FCntPsy | LCntPsy |\n",
    "| Emotional | Connection | Others influence my decisions | FConSoc | LConSoc |\n",
    "| Emotional | Balance | I'm anxious about change | FBalAnx | LBalAnx |\n",
    "| Emotional | Resources | I'm financially motivated | FResFin | LResFin |\n",
    "| Emotional | Control | I believe in myself | FContImp | LContImp |\n",
    "| Emotional | Journey | I'm optimistic about the future | FJouOpt | LJouOpt |\n",
    "| Emotional | Connection | I feel included | FConInc | LConInc |\n",
    "| Emotional | Balance | I'm happy where I am | FBalSat | LBalSat |\n",
    "| Emotional | Resources | I've got the skills to progress | FResSki | LResSki |\n",
    "| Emotional | Control | I control my next step | FContCon | LContCon |\n",
    "| Emotional | Journey | I've set myself goals | FJouPro | LJouPro |\n",
    "| Workplace/functional | Lack of opportunity to use skills/abilities | I can use my skills | FUseSkills | LUseSkills |\n",
    "| Workplace/functional | Learning and development | I have opportunities to learn | FLearnDev | LLearnDev |\n",
    "| Workplace/functional | Career advancement and promotions | I can grow here | Fcarprom | Lcarprom |\n",
    "| Workplace/functional | Meaning | I find my job meaningful | FMeanFull | LMeanFull |\n",
    "| Workplace/functional | Poor management | My manager is poor | Fpoorman | Lpoorman |\n",
    "| Workplace/functional | Toxic workplace/Company culture | The work culture is toxic | Ftoxic | Ltoxic |\n",
    "| Workplace/functional | Excessive or too little work | I'm working too hard | FExcessWk | LExcessWk |\n",
    "| Workplace/functional | Disagreement or fall out with colleagues | I don't get along with my colleagues | Fcollea | Lcollea |\n",
    "| Workplace/functional | A better salary and financial stability | I'm well compensated | Fwellcomp | Lwellcomp |\n",
    "| Workplace/functional | Financial fairness | My salary is unfair compared to colleagues | FFinFair | LFinLair |\n",
    "| Workplace/functional | Satisfaction around hybrid working | I enjoy hybrid working | Fenjhyb | Lenjhyb |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfa66a",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Firstly, clean our variable names, set our data types, and re-save the data for future loading/processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a4a7499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4211, 67)\n",
      "Data columns: Index(['batc_unnamed:_0', 'gend_unnamed:_1', 'age_unnamed:_2',\n",
      "       'pers_extraverted,_enthusiastic.', 'pers_critical,_quarrelsome.',\n",
      "       'pers_dependable,_self-disciplined.', 'pers_anxious,_easily_upset.',\n",
      "       'pers_open_to_new_experiences,_complex.', 'pers_sympathetic,_warm.',\n",
      "       'pers_disorganized,_careless.', 'pers_reserved,_quiet.',\n",
      "       'pers_calm,_emotionally_stable.', 'pers_conventional,_uncreative.',\n",
      "       'prep_unnamed:_13', 'qual_unnamed:_14',\n",
      "       'emot_emotional_likert.lbal_anx_', 'emot_emotional_likert.lbal_sat_',\n",
      "       'emot_emotional_likert.lcnt_com_', 'emot_emotional_likert.lcnt_psy_',\n",
      "       'emot_emotional_likert.lcon_inc_', 'emot_emotional_likert.lcon_soc_',\n",
      "       'emot_emotional_likert.lcont_con__',\n",
      "       'emot_emotional_likert.lcont_imp__', 'emot_emotional_likert.lgen__',\n",
      "       'emot_emotional_likert.ljou_opt__', 'emot_emotional_likert.ljou_pro__',\n",
      "       'emot_emotional_likert.lres_fin__', 'emot_emotional_likert.lres_ski__',\n",
      "       'emot_emotional_likert.ltra_aut__', 'emot_emotional_likert.ltra_des__',\n",
      "       'work_functional_likert.lcarprom_d', 'work_functional_likert.lcollea_',\n",
      "       'work_functional_likert.lenjhyb_', 'work_functional_likert.lexcess_wk_',\n",
      "       'work_functional_likert.lfin_lair_',\n",
      "       'work_functional_likert.llearn_dev_',\n",
      "       'work_functional_likert.lmean_full_',\n",
      "       'work_functional_likert.lpoorman_', 'work_functional_likert.ltoxic_',\n",
      "       'work_functional_likert.luse_skills_',\n",
      "       'work_functional_likert.lwellcomp_',\n",
      "       'emot_emotional_statements.fbal_anx__',\n",
      "       'emot_emotional_statements.fbal_sat__',\n",
      "       'emot_emotional_statements.fcnt_com__',\n",
      "       'emot_emotional_statements.fcnt_psy__',\n",
      "       'emot_emotional_statements.fcon_inc__',\n",
      "       'emot_emotional_statements.fcon_soc__',\n",
      "       'emot_emotional_statements.fcont_con__',\n",
      "       'emot_emotional_statements.fcont_imp__',\n",
      "       'emot_emotional_statements.fgen__',\n",
      "       'emot_emotional_statements.fjou_opt__',\n",
      "       'emot_emotional_statements.fjou_pro__',\n",
      "       'emot_emotional_statements.fres_fin__',\n",
      "       'emot_emotional_statements.fres_ski__',\n",
      "       'emot_emotional_statements.ftra_aut__',\n",
      "       'emot_emotional_statements.ftra_des__',\n",
      "       'work_functional_statements.fcarprom_',\n",
      "       'work_functional_statements.fcollea',\n",
      "       'work_functional_statements.fenjhyb_',\n",
      "       'work_functional_statements.fexcess_wk',\n",
      "       'work_functional_statements.ffin_fair_',\n",
      "       'work_functional_statements.flearn_dev',\n",
      "       'work_functional_statements.fmean_full_',\n",
      "       'work_functional_statements.fpoorman_',\n",
      "       'work_functional_statements.ftoxic_',\n",
      "       'work_functional_statements.fuse_skills',\n",
      "       'work_functional_statements.fwellcomp_'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhrou\\AppData\\Local\\Temp\\ipykernel_29776\\3271360133.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  nrows=1, header=None).iloc[0].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the data\n",
    "data = pd.read_excel(\"../data/CDS_25_Task1.xlsx\", sheet_name='Data', \n",
    "                    header=1, index_col=False)\n",
    "\n",
    "# Quick rename with category prefixes\n",
    "cats = pd.read_excel(\"../data/CDS_25_Task1.xlsx\", sheet_name='Data', \n",
    "                    nrows=1, header=None).iloc[0].fillna(method='ffill')\n",
    "\n",
    "data.columns = [f\"{'pers' if 'personality' in str(cat).lower() else str(cat)[:4]}_{col}\".lower().replace(' ', '_') \n",
    "                for cat, col in zip(cats, data.columns)]\n",
    "\n",
    "data.head()\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "print(f\"Data columns: {data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e1a521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['batch', 'gender', 'age', 'pers_extraverted_enthusiastic',\n",
       "       'pers_critical_quarrelsome', 'pers_dependable_self-disciplined',\n",
       "       'pers_anxious_easily_upset', 'pers_open_to_new_experiences_complex',\n",
       "       'pers_sympathetic_warm', 'pers_disorganized_careless',\n",
       "       'pers_reserved_quiet', 'pers_calm_emotionally_stable',\n",
       "       'pers_conventional_uncreative', 'prep_level', 'qual_reasons',\n",
       "       'el_lbal_anx', 'el_lbal_sat', 'el_lcnt_com', 'el_lcnt_psy',\n",
       "       'el_lcon_inc', 'el_lcon_soc', 'el_lcont_con', 'el_lcont_imp', 'el_lgen',\n",
       "       'el_ljou_opt', 'el_ljou_pro', 'el_lres_fin', 'el_lres_ski',\n",
       "       'el_ltra_aut', 'el_ltra_des', 'wfl_lcarprom_d', 'wfl_lcollea',\n",
       "       'wfl_lenjhyb', 'wfl_lexcess_wk', 'wfl_lfin_lair', 'wfl_llearn_dev',\n",
       "       'wfl_lmean_full', 'wfl_lpoorman', 'wfl_ltoxic', 'wfl_luse_skills',\n",
       "       'wfl_lwellcomp', 'es_fbal_anx', 'es_fbal_sat', 'es_fcnt_com',\n",
       "       'es_fcnt_psy', 'es_fcon_inc', 'es_fcon_soc', 'es_fcont_con',\n",
       "       'es_fcont_imp', 'es_fgen', 'es_fjou_opt', 'es_fjou_pro', 'es_fres_fin',\n",
       "       'es_fres_ski', 'es_ftra_aut', 'es_ftra_des', 'wfs_fcarprom',\n",
       "       'wfs_fcollea', 'wfs_fenjhyb', 'wfs_fexcess_wk', 'wfs_ffin_fair',\n",
       "       'wfs_flearn_dev', 'wfs_fmean_full', 'wfs_fpoorman', 'wfs_ftoxic',\n",
       "       'wfs_fuse_skills', 'wfs_fwellcomp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean column names\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Clean dataframe column names using simple string operations\"\"\"\n",
    "    \n",
    "    # Create mapping dictionary\n",
    "    name_mapping = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        new_name = col\n",
    "        \n",
    "        # Handle specific replacements first\n",
    "        if col == 'batc_unnamed:_0':\n",
    "            new_name = 'batch'\n",
    "        elif col == 'gend_unnamed:_1':\n",
    "            new_name = 'gender'\n",
    "        elif col == 'age_unnamed:_2':\n",
    "            new_name = 'age'\n",
    "        elif col == 'prep_unnamed:_13':\n",
    "            new_name = 'prep_level'\n",
    "        elif col == 'qual_unnamed:_14':\n",
    "            new_name = 'qual_reasons'\n",
    "        else:\n",
    "            # Replace long prefixes with short codes\n",
    "            new_name = new_name.replace('emot_emotional_statements', 'es') # change to 'es' emotional statements (fast choice response)\n",
    "            new_name = new_name.replace('emot_emotional_likert', 'el') # change to workplace/functional likert, wfl\n",
    "            new_name = new_name.replace('work_functional_statements', 'wfs') #change workplace/functional statements (fast choice response)\n",
    "            new_name = new_name.replace('work_functional_likert', 'wfl') # change workplace/functional likert, wfl\n",
    "            \n",
    "            # Replace periods with underscores\n",
    "            new_name = new_name.replace('.', '_')\n",
    "            \n",
    "            # Remove commas\n",
    "            new_name = new_name.replace(',', '')\n",
    "            \n",
    "            # Remove trailing underscores\n",
    "            new_name = new_name.rstrip('_')\n",
    "        \n",
    "        name_mapping[col] = new_name\n",
    "    \n",
    "    # Apply the mapping\n",
    "    df_cleaned = df.rename(columns=name_mapping)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "data = clean_column_names(data)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bec65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL VARIABLES ===\n",
      "batch: 7 unique values\n",
      "Values: ['FR Tech' 'DE Fin' 'SP Fin' 'US Pharma' 'IT Fin' 'UK Energy' 'US Tech']\n",
      "\n",
      "gender: 5 unique values\n",
      "Values: ['Female' 'Male' 'Non-Binary / Non-Conforming' 'Prefer Not to Answer'\n",
      " 'Other']\n",
      "\n",
      "age: 3 unique values\n",
      "Values: ['18-24' '25-40' '41-64']\n",
      "\n",
      "qual_reasons: 4107 unique values\n",
      "Values: ['Je suis prête à m’engager, organise'\n",
      " 'Jeune diplôme je suis prête à entrer dans le monde professionnel sur un emploi stable et sur du long terme'\n",
      " 'La nouvelle technologie, les nouveaux moyens mit en place…' ...\n",
      " 'Italian reasons' 'El Reasons' 'Reasons Spanish']\n",
      "\n",
      "=== PERSONALITY VARIABLES ===\n",
      "pers_extraverted_enthusiastic: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_critical_quarrelsome: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_dependable_self-disciplined: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_anxious_easily_upset: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_open_to_new_experiences_complex: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_sympathetic_warm: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_disorganized_careless: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_reserved_quiet: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_calm_emotionally_stable: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "pers_conventional_uncreative: 1-7, values: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "\n",
      "=== LIKERT VARIABLES ===\n",
      "el_lbal_anx: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lbal_sat: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcnt_com: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcnt_psy: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcon_inc: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcon_soc: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcont_con: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lcont_imp: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lgen: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ljou_opt: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ljou_pro: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lres_fin: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_lres_ski: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ltra_aut: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "el_ltra_des: -100-100, values: [np.int64(-100), np.int64(-75), np.int64(-50), np.int64(-25), np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lcarprom_d: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lcollea: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lenjhyb: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lexcess_wk: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_lfin_lair: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_llearn_dev: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_lmean_full: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_lpoorman: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_ltoxic: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "wfl_luse_skills: 0.0-100.0, values: [np.float64(0.0), np.float64(25.0), np.float64(50.0), np.float64(75.0), np.float64(100.0)]\n",
      "wfl_lwellcomp: 0-100, values: [np.int64(0), np.int64(25), np.int64(50), np.int64(75), np.int64(100)]\n",
      "\n",
      "=== FACTOR VARIABLES ===\n",
      "es_fbal_anx: range -94.444 to 98.889, 512 unique values\n",
      "es_fbal_sat: range -96.667 to 98.889, 541 unique values\n",
      "es_fcnt_com: range -98.889 to 97.778, 547 unique values\n",
      "es_fcnt_psy: range -97.222 to 98.889, 530 unique values\n",
      "es_fcon_inc: range -98.889 to 97.778, 544 unique values\n",
      "es_fcon_soc: range -98.889 to 97.778, 507 unique values\n",
      "es_fcont_con: range -96.667 to 97.778, 510 unique values\n",
      "es_fcont_imp: range -98.889 to 98.889, 505 unique values\n",
      "es_fgen: range -96.667 to 98.889, 499 unique values\n",
      "es_fjou_opt: range -96.667 to 96.667, 549 unique values\n",
      "es_fjou_pro: range -98.889 to 96.667, 521 unique values\n",
      "es_fres_fin: range -98.889 to 98.889, 521 unique values\n",
      "es_fres_ski: range -98.889 to 98.889, 508 unique values\n",
      "es_ftra_aut: range -96.111 to 98.889, 520 unique values\n",
      "es_ftra_des: range -98.889 to 98.889, 513 unique values\n",
      "wfs_fcarprom: range 0.000 to 100.000, 177 unique values\n",
      "wfs_fcollea: range 0.000 to 100.000, 187 unique values\n",
      "wfs_fenjhyb: range 0.000 to 100.000, 189 unique values\n",
      "wfs_fexcess_wk: range 0.000 to 100.000, 185 unique values\n",
      "wfs_ffin_fair: range 0.000 to 100.000, 184 unique values\n",
      "wfs_flearn_dev: range 0.000 to 100.000, 174 unique values\n",
      "wfs_fmean_full: range 0.000 to 100.000, 180 unique values\n",
      "wfs_fpoorman: range 0.000 to 100.000, 189 unique values\n",
      "wfs_ftoxic: range 0.000 to 100.000, 185 unique values\n",
      "wfs_fuse_skills: range 0.000 to 100.000, 173 unique values\n",
      "wfs_fwellcomp: range 0.000 to 100.000, 183 unique values\n",
      "\n",
      "=== PREP LEVEL ===\n",
      "prep_level: 1.0 to 10.0\n",
      "Values: [np.float64(1.0), np.float64(1.1), np.float64(1.2), np.float64(1.3), np.float64(1.5), np.float64(1.7), np.float64(1.8), np.float64(1.9), np.float64(2.0), np.float64(2.1), np.float64(2.2), np.float64(2.3), np.float64(2.4), np.float64(2.6), np.float64(2.7), np.float64(2.8), np.float64(2.9), np.float64(3.0), np.float64(3.1), np.float64(3.2), np.float64(3.3), np.float64(3.4), np.float64(3.5), np.float64(3.6), np.float64(3.7), np.float64(3.8), np.float64(3.9), np.float64(4.0), np.float64(4.1), np.float64(4.2), np.float64(4.3), np.float64(4.4), np.float64(4.5), np.float64(4.6), np.float64(4.7), np.float64(4.8), np.float64(4.9), np.float64(5.0), np.float64(5.1), np.float64(5.2), np.float64(5.3), np.float64(5.4), np.float64(5.5), np.float64(5.6), np.float64(5.7), np.float64(5.8), np.float64(5.9), np.float64(6.0), np.float64(6.1), np.float64(6.2), np.float64(6.3), np.float64(6.4), np.float64(6.5), np.float64(6.6), np.float64(6.7), np.float64(6.8), np.float64(6.9), np.float64(7.0), np.float64(7.1), np.float64(7.2), np.float64(7.3), np.float64(7.4), np.float64(7.5), np.float64(7.6), np.float64(7.7), np.float64(7.8), np.float64(7.9), np.float64(8.0), np.float64(8.1), np.float64(8.2), np.float64(8.3), np.float64(8.4), np.float64(8.5), np.float64(8.6), np.float64(8.7), np.float64(8.8), np.float64(8.9), np.float64(9.0), np.float64(9.1), np.float64(9.2), np.float64(9.3), np.float64(9.4), np.float64(9.5), np.float64(9.6), np.float64(9.7), np.float64(9.8), np.float64(9.9), np.float64(10.0)]\n",
      "prep_level\n",
      "1.0      1\n",
      "1.1      2\n",
      "1.2      1\n",
      "1.3      1\n",
      "1.5      1\n",
      "        ..\n",
      "9.6     59\n",
      "9.7     20\n",
      "9.8     14\n",
      "9.9     18\n",
      "10.0     1\n",
      "Name: count, Length: 88, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploring our variable ranges and unique values\n",
    "\n",
    "# Categorical variables\n",
    "print(\"=== CATEGORICAL VARIABLES ===\")\n",
    "for col in ['batch', 'gender', 'age', 'qual_reasons']:\n",
    "    if col in data.columns:\n",
    "        print(f\"{col}: {data[col].nunique()} unique values\")\n",
    "        print(f\"Values: {data[col].unique()}\")\n",
    "        print()\n",
    "\n",
    "# Personality variables (pers_)\n",
    "print(\"=== PERSONALITY VARIABLES ===\")\n",
    "pers_cols = [col for col in data.columns if col.startswith('pers_')]\n",
    "for col in pers_cols:\n",
    "    unique_vals = sorted(data[col].unique())\n",
    "    print(f\"{col}: {min(unique_vals)}-{max(unique_vals)}, values: {unique_vals}\")\n",
    "\n",
    "# Likert variables (eml_, wfl_)\n",
    "print(\"\\n=== LIKERT VARIABLES ===\")\n",
    "likert_cols = [col for col in data.columns if col.startswith(('el_', 'wfl_'))]\n",
    "for col in likert_cols:\n",
    "    unique_vals = sorted(data[col].dropna().unique())\n",
    "    print(f\"{col}: {min(unique_vals)}-{max(unique_vals)}, values: {unique_vals}\")\n",
    "\n",
    "# Factor variables (emt_, wfs_)\n",
    "print(\"\\n=== FACTOR VARIABLES ===\")\n",
    "factor_cols = [col for col in data.columns if col.startswith(('es_', 'wfs_'))]\n",
    "for col in factor_cols:\n",
    "    non_null = data[col].dropna()\n",
    "    if len(non_null) > 0:\n",
    "        print(f\"{col}: range {non_null.min():.3f} to {non_null.max():.3f}, {non_null.nunique()} unique values\")\n",
    "\n",
    "# Prep level\n",
    "print(\"\\n=== PREP LEVEL ===\")\n",
    "prep_vals = sorted(data['prep_level'].dropna().unique())\n",
    "print(f\"prep_level: {min(prep_vals)} to {max(prep_vals)}\")\n",
    "print(f\"Values: {prep_vals}\")\n",
    "print(data['prep_level'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c7cab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above, we can appropriately set our data types\n",
    "# Convert categorical variables to category dtype\n",
    "data['batch'] = data['batch'].astype('category')\n",
    "data['gender'] = data['gender'].astype('category') \n",
    "data['qual_reasons'] = data['qual_reasons'].astype('object') # Keep qualitative as a string\n",
    "\n",
    "# Age as ordered categorical\n",
    "age_dtype = pd.CategoricalDtype(categories=['18-24', '25-40', '41-64'], ordered=True)\n",
    "data['age'] = data['age'].astype(age_dtype)\n",
    "\n",
    "# Personality variables (1-7 scale) - convert to integers for better model compatibility\n",
    "pers_cols = [col for col in data.columns if col.startswith('pers_')]\n",
    "for col in pers_cols:\n",
    "    data[col] = data[col].astype('Int64')  # nullable integer type\n",
    "\n",
    "# EL Likert variables (-100 to 100, steps of 25) - convert to integers\n",
    "el_cols = [col for col in data.columns if col.startswith('el_')]\n",
    "for col in el_cols:\n",
    "    data[col] = data[col].astype('Int64')  # nullable integer type\n",
    "\n",
    "# WFL Likert variables (0 to 100, steps of 25) - convert to integers\n",
    "wfl_cols = [col for col in data.columns if col.startswith('wfl_')]\n",
    "for col in wfl_cols:\n",
    "    data[col] = data[col].astype('Int64')  # nullable integer type\n",
    "\n",
    "# Factor variables - keep as float32 (continuous scores, need decimal precision)\n",
    "emt_cols = [col for col in data.columns if col.startswith('es_')]\n",
    "for col in emt_cols:\n",
    "    data[col] = data[col].astype('float32')\n",
    "\n",
    "wfs_cols = [col for col in data.columns if col.startswith('wfs_')]\n",
    "for col in wfs_cols:\n",
    "    data[col] = data[col].astype('float32')\n",
    "\n",
    "# Prep level - keep as float32 (has decimal values)\n",
    "data['prep_level'] = data['prep_level'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c470a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4211 entries, 0 to 4210\n",
      "Data columns (total 67 columns):\n",
      " #   Column                                Non-Null Count  Dtype   \n",
      "---  ------                                --------------  -----   \n",
      " 0   batch                                 4211 non-null   category\n",
      " 1   gender                                4211 non-null   category\n",
      " 2   age                                   4211 non-null   category\n",
      " 3   pers_extraverted_enthusiastic         4211 non-null   Int64   \n",
      " 4   pers_critical_quarrelsome             4211 non-null   Int64   \n",
      " 5   pers_dependable_self-disciplined      4211 non-null   Int64   \n",
      " 6   pers_anxious_easily_upset             4211 non-null   Int64   \n",
      " 7   pers_open_to_new_experiences_complex  4211 non-null   Int64   \n",
      " 8   pers_sympathetic_warm                 4211 non-null   Int64   \n",
      " 9   pers_disorganized_careless            4211 non-null   Int64   \n",
      " 10  pers_reserved_quiet                   4211 non-null   Int64   \n",
      " 11  pers_calm_emotionally_stable          4211 non-null   Int64   \n",
      " 12  pers_conventional_uncreative          4211 non-null   Int64   \n",
      " 13  prep_level                            4211 non-null   float32 \n",
      " 14  qual_reasons                          4189 non-null   object  \n",
      " 15  el_lbal_anx                           4211 non-null   Int64   \n",
      " 16  el_lbal_sat                           4211 non-null   Int64   \n",
      " 17  el_lcnt_com                           4211 non-null   Int64   \n",
      " 18  el_lcnt_psy                           4211 non-null   Int64   \n",
      " 19  el_lcon_inc                           4211 non-null   Int64   \n",
      " 20  el_lcon_soc                           4211 non-null   Int64   \n",
      " 21  el_lcont_con                          4211 non-null   Int64   \n",
      " 22  el_lcont_imp                          4211 non-null   Int64   \n",
      " 23  el_lgen                               4211 non-null   Int64   \n",
      " 24  el_ljou_opt                           4211 non-null   Int64   \n",
      " 25  el_ljou_pro                           4211 non-null   Int64   \n",
      " 26  el_lres_fin                           4211 non-null   Int64   \n",
      " 27  el_lres_ski                           4211 non-null   Int64   \n",
      " 28  el_ltra_aut                           4211 non-null   Int64   \n",
      " 29  el_ltra_des                           4211 non-null   Int64   \n",
      " 30  wfl_lcarprom_d                        4211 non-null   Int64   \n",
      " 31  wfl_lcollea                           4211 non-null   Int64   \n",
      " 32  wfl_lenjhyb                           4211 non-null   Int64   \n",
      " 33  wfl_lexcess_wk                        4210 non-null   Int64   \n",
      " 34  wfl_lfin_lair                         4210 non-null   Int64   \n",
      " 35  wfl_llearn_dev                        4211 non-null   Int64   \n",
      " 36  wfl_lmean_full                        4210 non-null   Int64   \n",
      " 37  wfl_lpoorman                          4211 non-null   Int64   \n",
      " 38  wfl_ltoxic                            4211 non-null   Int64   \n",
      " 39  wfl_luse_skills                       4210 non-null   Int64   \n",
      " 40  wfl_lwellcomp                         4211 non-null   Int64   \n",
      " 41  es_fbal_anx                           4210 non-null   float32 \n",
      " 42  es_fbal_sat                           4211 non-null   float32 \n",
      " 43  es_fcnt_com                           4211 non-null   float32 \n",
      " 44  es_fcnt_psy                           4211 non-null   float32 \n",
      " 45  es_fcon_inc                           4211 non-null   float32 \n",
      " 46  es_fcon_soc                           4209 non-null   float32 \n",
      " 47  es_fcont_con                          4210 non-null   float32 \n",
      " 48  es_fcont_imp                          4210 non-null   float32 \n",
      " 49  es_fgen                               4210 non-null   float32 \n",
      " 50  es_fjou_opt                           4211 non-null   float32 \n",
      " 51  es_fjou_pro                           4209 non-null   float32 \n",
      " 52  es_fres_fin                           4206 non-null   float32 \n",
      " 53  es_fres_ski                           4211 non-null   float32 \n",
      " 54  es_ftra_aut                           4211 non-null   float32 \n",
      " 55  es_ftra_des                           4210 non-null   float32 \n",
      " 56  wfs_fcarprom                          4210 non-null   float32 \n",
      " 57  wfs_fcollea                           4211 non-null   float32 \n",
      " 58  wfs_fenjhyb                           4211 non-null   float32 \n",
      " 59  wfs_fexcess_wk                        4211 non-null   float32 \n",
      " 60  wfs_ffin_fair                         4211 non-null   float32 \n",
      " 61  wfs_flearn_dev                        4211 non-null   float32 \n",
      " 62  wfs_fmean_full                        4211 non-null   float32 \n",
      " 63  wfs_fpoorman                          4211 non-null   float32 \n",
      " 64  wfs_ftoxic                            4208 non-null   float32 \n",
      " 65  wfs_fuse_skills                       4209 non-null   float32 \n",
      " 66  wfs_fwellcomp                         4211 non-null   float32 \n",
      "dtypes: Int64(36), category(3), float32(27), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54964da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     Je suis prête à m’engager, organise\n",
      "1       Jeune diplôme je suis prête à entrer dans le m...\n",
      "2       La nouvelle technologie, les nouveaux moyens m...\n",
      "3       Je suis prete à passer a une nouvelle étape de...\n",
      "4       Sa fait 4ans  que je suis en poste de chef d'é...\n",
      "                              ...                        \n",
      "4206    I am willing and ready for the next set of que...\n",
      "4207                                         Cody Reasons\n",
      "4208                                      Italian reasons\n",
      "4209                                           El Reasons\n",
      "4210                                      Reasons Spanish\n",
      "Name: qual_reasons, Length: 4211, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Little bit worried about the encoding of qualitative responses as text data, since there's so many languages and unique characters\n",
    "print(data.loc[:,'qual_reasons'])\n",
    "\n",
    "# Should bear this in mind for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a278ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sector</th>\n",
       "      <th>country_sector</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pers_extraverted_enthusiastic</th>\n",
       "      <th>pers_critical_quarrelsome</th>\n",
       "      <th>pers_dependable_self-disciplined</th>\n",
       "      <th>pers_anxious_easily_upset</th>\n",
       "      <th>pers_open_to_new_experiences_complex</th>\n",
       "      <th>...</th>\n",
       "      <th>wfs_fcollea</th>\n",
       "      <th>wfs_fenjhyb</th>\n",
       "      <th>wfs_fexcess_wk</th>\n",
       "      <th>wfs_ffin_fair</th>\n",
       "      <th>wfs_flearn_dev</th>\n",
       "      <th>wfs_fmean_full</th>\n",
       "      <th>wfs_fpoorman</th>\n",
       "      <th>wfs_ftoxic</th>\n",
       "      <th>wfs_fuse_skills</th>\n",
       "      <th>wfs_fwellcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.555555</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>44.444443</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>63.333332</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>97.777779</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>37.777779</td>\n",
       "      <td>57.777779</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>92.222221</td>\n",
       "      <td>67.777779</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>16.666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>56.666668</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>72.222221</td>\n",
       "      <td>83.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>62.222221</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>27.777779</td>\n",
       "      <td>96.666664</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>22.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>91.111115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>84.444443</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.555557</td>\n",
       "      <td>98.888885</td>\n",
       "      <td>83.333336</td>\n",
       "      <td>58.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country sector country_sector  gender    age  pers_extraverted_enthusiastic  \\\n",
       "0      FR   Tech        FR Tech  Female  18-24                              5   \n",
       "1      FR   Tech        FR Tech  Female  18-24                              5   \n",
       "2      FR   Tech        FR Tech  Female  18-24                              2   \n",
       "3      FR   Tech        FR Tech  Female  25-40                              4   \n",
       "4      FR   Tech        FR Tech  Female  25-40                              7   \n",
       "\n",
       "   pers_critical_quarrelsome  pers_dependable_self-disciplined  \\\n",
       "0                          1                                 7   \n",
       "1                          2                                 6   \n",
       "2                          3                                 1   \n",
       "3                          6                                 1   \n",
       "4                          5                                 7   \n",
       "\n",
       "   pers_anxious_easily_upset  pers_open_to_new_experiences_complex  ...  \\\n",
       "0                          3                                     7  ...   \n",
       "1                          3                                     7  ...   \n",
       "2                          4                                     2  ...   \n",
       "3                          3                                     4  ...   \n",
       "4                          5                                     7  ...   \n",
       "\n",
       "   wfs_fcollea  wfs_fenjhyb  wfs_fexcess_wk  wfs_ffin_fair  wfs_flearn_dev  \\\n",
       "0    15.555555    65.555557       25.555555      44.444443       86.666664   \n",
       "1    48.888889    37.777779       57.777779      65.555557       76.666664   \n",
       "2    86.666664    60.000000       56.666668      48.888889       76.666664   \n",
       "3    25.555555    62.222221       40.000000      27.777779       96.666664   \n",
       "4    91.111115     0.000000       93.333336      90.000000       84.444443   \n",
       "\n",
       "   wfs_fmean_full wfs_fpoorman  wfs_ftoxic  wfs_fuse_skills  wfs_fwellcomp  \n",
       "0       63.333332    20.000000   97.777779        91.666664     100.000000  \n",
       "1       77.777779    92.222221   67.777779        93.333336      16.666666  \n",
       "2       91.666664    30.000000   38.888889        72.222221      83.333336  \n",
       "3       21.111111    70.000000   20.000000        93.333336      22.777779  \n",
       "4       70.000000    75.555557   98.888885        83.333336      58.888889  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split batch group column between country and sector by space delimiter\n",
    "data[['country', 'sector']] = data['batch'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# Drop the original batch column - removed because we actually need batch in regression down the line\n",
    "#data.drop(columns=['batch'], inplace=True)\n",
    "\n",
    "# rename batch to country_sector\n",
    "data.rename(columns={'batch': 'country_sector'}, inplace=True)\n",
    "\n",
    "# set the new columns as first two columns\n",
    "data = data[['country', 'sector'] + [col for col in data.columns if col not in ['country', 'sector']]]\n",
    "\n",
    "# remove index column if it exists\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99838dba",
   "metadata": {},
   "source": [
    "Now we've got our data cleaned and formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede7908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sector</th>\n",
       "      <th>country_sector</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pers_extraverted_enthusiastic</th>\n",
       "      <th>pers_critical_quarrelsome</th>\n",
       "      <th>pers_dependable_self-disciplined</th>\n",
       "      <th>pers_anxious_easily_upset</th>\n",
       "      <th>pers_open_to_new_experiences_complex</th>\n",
       "      <th>...</th>\n",
       "      <th>wfs_fcollea</th>\n",
       "      <th>wfs_fenjhyb</th>\n",
       "      <th>wfs_fexcess_wk</th>\n",
       "      <th>wfs_ffin_fair</th>\n",
       "      <th>wfs_flearn_dev</th>\n",
       "      <th>wfs_fmean_full</th>\n",
       "      <th>wfs_fpoorman</th>\n",
       "      <th>wfs_ftoxic</th>\n",
       "      <th>wfs_fuse_skills</th>\n",
       "      <th>wfs_fwellcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.555555</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>44.444443</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>63.333332</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>97.777779</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>37.777779</td>\n",
       "      <td>57.777779</td>\n",
       "      <td>65.555557</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>92.222221</td>\n",
       "      <td>67.777779</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>16.666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>56.666668</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>76.666664</td>\n",
       "      <td>91.666664</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>72.222221</td>\n",
       "      <td>83.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>25.555555</td>\n",
       "      <td>62.222221</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>27.777779</td>\n",
       "      <td>96.666664</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>22.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>Tech</td>\n",
       "      <td>FR Tech</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-40</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>91.111115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.333336</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>84.444443</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.555557</td>\n",
       "      <td>98.888885</td>\n",
       "      <td>83.333336</td>\n",
       "      <td>58.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country sector country_sector  gender    age  pers_extraverted_enthusiastic  \\\n",
       "0      FR   Tech        FR Tech  Female  18-24                              5   \n",
       "1      FR   Tech        FR Tech  Female  18-24                              5   \n",
       "2      FR   Tech        FR Tech  Female  18-24                              2   \n",
       "3      FR   Tech        FR Tech  Female  25-40                              4   \n",
       "4      FR   Tech        FR Tech  Female  25-40                              7   \n",
       "\n",
       "   pers_critical_quarrelsome  pers_dependable_self-disciplined  \\\n",
       "0                          1                                 7   \n",
       "1                          2                                 6   \n",
       "2                          3                                 1   \n",
       "3                          6                                 1   \n",
       "4                          5                                 7   \n",
       "\n",
       "   pers_anxious_easily_upset  pers_open_to_new_experiences_complex  ...  \\\n",
       "0                          3                                     7  ...   \n",
       "1                          3                                     7  ...   \n",
       "2                          4                                     2  ...   \n",
       "3                          3                                     4  ...   \n",
       "4                          5                                     7  ...   \n",
       "\n",
       "   wfs_fcollea  wfs_fenjhyb  wfs_fexcess_wk  wfs_ffin_fair  wfs_flearn_dev  \\\n",
       "0    15.555555    65.555557       25.555555      44.444443       86.666664   \n",
       "1    48.888889    37.777779       57.777779      65.555557       76.666664   \n",
       "2    86.666664    60.000000       56.666668      48.888889       76.666664   \n",
       "3    25.555555    62.222221       40.000000      27.777779       96.666664   \n",
       "4    91.111115     0.000000       93.333336      90.000000       84.444443   \n",
       "\n",
       "   wfs_fmean_full wfs_fpoorman  wfs_ftoxic  wfs_fuse_skills  wfs_fwellcomp  \n",
       "0       63.333332    20.000000   97.777779        91.666664     100.000000  \n",
       "1       77.777779    92.222221   67.777779        93.333336      16.666666  \n",
       "2       91.666664    30.000000   38.888889        72.222221      83.333336  \n",
       "3       21.111111    70.000000   20.000000        93.333336      22.777779  \n",
       "4       70.000000    75.555557   98.888885        83.333336      58.888889  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db24f52",
   "metadata": {},
   "source": [
    "Let's also check for missing values and any unique encoding schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "324fa30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECKING FOR MISSING VALUE INDICATORS ===\n",
      "\n",
      "country:\n",
      "  OK\n",
      "sector:\n",
      "  OK\n",
      "country_sector:\n",
      "  OK\n",
      "gender:\n",
      "  OK\n",
      "age:\n",
      "  OK\n",
      "pers_extraverted_enthusiastic:\n",
      "  OK\n",
      "pers_critical_quarrelsome:\n",
      "  OK\n",
      "pers_dependable_self-disciplined:\n",
      "  OK\n",
      "pers_anxious_easily_upset:\n",
      "  OK\n",
      "pers_open_to_new_experiences_complex:\n",
      "  OK\n",
      "pers_sympathetic_warm:\n",
      "  OK\n",
      "pers_disorganized_careless:\n",
      "  OK\n",
      "pers_reserved_quiet:\n",
      "  OK\n",
      "pers_calm_emotionally_stable:\n",
      "  OK\n",
      "pers_conventional_uncreative:\n",
      "  OK\n",
      "prep_level:\n",
      "  OK (88 unique values)\n",
      "qual_reasons:\n",
      "  SUSPICIOUS: ['-']\n",
      "el_lbal_anx:\n",
      "  OK\n",
      "el_lbal_sat:\n",
      "  OK\n",
      "el_lcnt_com:\n",
      "  OK\n",
      "el_lcnt_psy:\n",
      "  OK\n",
      "el_lcon_inc:\n",
      "  OK\n",
      "el_lcon_soc:\n",
      "  OK\n",
      "el_lcont_con:\n",
      "  OK\n",
      "el_lcont_imp:\n",
      "  OK\n",
      "el_lgen:\n",
      "  OK\n",
      "el_ljou_opt:\n",
      "  OK\n",
      "el_ljou_pro:\n",
      "  OK\n",
      "el_lres_fin:\n",
      "  OK\n",
      "el_lres_ski:\n",
      "  OK\n",
      "el_ltra_aut:\n",
      "  OK\n",
      "el_ltra_des:\n",
      "  OK\n",
      "wfl_lcarprom_d:\n",
      "  OK\n",
      "wfl_lcollea:\n",
      "  OK\n",
      "wfl_lenjhyb:\n",
      "  OK\n",
      "wfl_lexcess_wk:\n",
      "  OK\n",
      "wfl_lfin_lair:\n",
      "  OK\n",
      "wfl_llearn_dev:\n",
      "  OK\n",
      "wfl_lmean_full:\n",
      "  OK\n",
      "wfl_lpoorman:\n",
      "  OK\n",
      "wfl_ltoxic:\n",
      "  OK\n",
      "wfl_luse_skills:\n",
      "  OK\n",
      "wfl_lwellcomp:\n",
      "  OK\n",
      "es_fbal_anx:\n",
      "  OK (326 unique values)\n",
      "es_fbal_sat:\n",
      "  OK (335 unique values)\n",
      "es_fcnt_com:\n",
      "  OK (338 unique values)\n",
      "es_fcnt_psy:\n",
      "  OK (327 unique values)\n",
      "es_fcon_inc:\n",
      "  OK (342 unique values)\n",
      "es_fcon_soc:\n",
      "  OK (318 unique values)\n",
      "es_fcont_con:\n",
      "  OK (330 unique values)\n",
      "es_fcont_imp:\n",
      "  OK (332 unique values)\n",
      "es_fgen:\n",
      "  OK (311 unique values)\n",
      "es_fjou_opt:\n",
      "  OK (339 unique values)\n",
      "es_fjou_pro:\n",
      "  OK (330 unique values)\n",
      "es_fres_fin:\n",
      "  OK (328 unique values)\n",
      "es_fres_ski:\n",
      "  OK (320 unique values)\n",
      "es_ftra_aut:\n",
      "  OK (329 unique values)\n",
      "es_ftra_des:\n",
      "  OK (330 unique values)\n",
      "wfs_fcarprom:\n",
      "  OK (178 unique values)\n",
      "wfs_fcollea:\n",
      "  OK (187 unique values)\n",
      "wfs_fenjhyb:\n",
      "  OK (189 unique values)\n",
      "wfs_fexcess_wk:\n",
      "  OK (185 unique values)\n",
      "wfs_ffin_fair:\n",
      "  OK (184 unique values)\n",
      "wfs_flearn_dev:\n",
      "  OK (174 unique values)\n",
      "wfs_fmean_full:\n",
      "  OK (180 unique values)\n",
      "wfs_fpoorman:\n",
      "  OK (189 unique values)\n",
      "wfs_ftoxic:\n",
      "  OK (186 unique values)\n",
      "wfs_fuse_skills:\n",
      "  OK (174 unique values)\n",
      "wfs_fwellcomp:\n",
      "  OK (183 unique values)\n",
      "\n",
      "=== MISSING DATA SUMMARY ===\n",
      "qual_reasons       22\n",
      "wfl_lexcess_wk      1\n",
      "wfl_lfin_lair       1\n",
      "wfl_lmean_full      1\n",
      "wfl_luse_skills     1\n",
      "es_fbal_anx         1\n",
      "es_fcon_soc         2\n",
      "es_fcont_con        1\n",
      "es_fcont_imp        1\n",
      "es_fgen             1\n",
      "es_fjou_pro         2\n",
      "es_fres_fin         5\n",
      "es_ftra_des         1\n",
      "wfs_fcarprom        1\n",
      "wfs_ftoxic          3\n",
      "wfs_fuse_skills     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values and recode any non-response indicators as NA\n",
    "\n",
    "# Check for common missing value indicators\n",
    "missing_indicators = ['', ' ', 'NA', 'N/A', 'null', 'NULL', 'None', 'NONE', \n",
    "                     'missing', 'Missing', 'MISSING', '?', '-', '--', \n",
    "                     '999', '-999', '9999', '-9999', '99', '-99']\n",
    "\n",
    "print(\"=== CHECKING FOR MISSING VALUE INDICATORS ===\\n\")\n",
    "\n",
    "# Check each column for potential missing indicators\n",
    "for col in data.columns:\n",
    "    print(f\"{col}:\")\n",
    "    \n",
    "    # Get unique values (first 10 and last 10 if many)\n",
    "    unique_vals = data[col].unique()\n",
    "    \n",
    "    if len(unique_vals) <= 20:\n",
    "        suspicious = [val for val in unique_vals if str(val) in missing_indicators]\n",
    "        if suspicious:\n",
    "            print(f\"  SUSPICIOUS: {suspicious}\")\n",
    "        else:\n",
    "            print(f\"  OK\")\n",
    "    else:\n",
    "        # For columns with many unique values, just check if any missing indicators present\n",
    "        suspicious = [val for val in unique_vals if str(val) in missing_indicators]\n",
    "        if suspicious:\n",
    "            print(f\"  SUSPICIOUS: {suspicious}\")\n",
    "        else:\n",
    "            print(f\"  OK ({len(unique_vals)} unique values)\")\n",
    "    \n",
    "    # Also check for unusual patterns in numeric columns\n",
    "    if data[col].dtype in ['int64', 'float64', 'int8', 'float32']:\n",
    "        numeric_vals = pd.to_numeric(data[col], errors='coerce')\n",
    "        \n",
    "        # Check for extreme values that might be missing indicators\n",
    "        if not numeric_vals.isna().all():\n",
    "            min_val, max_val = numeric_vals.min(), numeric_vals.max()\n",
    "            \n",
    "            # Flag if we see common missing codes\n",
    "            extreme_vals = numeric_vals[numeric_vals.isin([99, -99, 999, -999, 9999, -9999])]\n",
    "            if len(extreme_vals) > 0:\n",
    "                print(f\"  EXTREME VALUES: {extreme_vals.unique()}\")\n",
    "\n",
    "print(\"\\n=== MISSING DATA SUMMARY ===\")\n",
    "print(data.isnull().sum()[data.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e92fa",
   "metadata": {},
   "source": [
    "Finally let's save our data for further analysis. To preserve our data types, let's save as a pickle file, rather than csv. \n",
    "Also let's add an md file as our codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49212435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle file\n",
    "data.to_pickle(\"../data/survey_data_cleaned.pkl\")\n",
    "\n",
    "# save as csv file, making sure to check data types when loading it in\n",
    "data.to_csv(\"../data/survey_data_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301ce889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4211 entries, 0 to 4210\n",
      "Data columns (total 68 columns):\n",
      " #   Column                                Non-Null Count  Dtype   \n",
      "---  ------                                --------------  -----   \n",
      " 0   country                               4211 non-null   object  \n",
      " 1   sector                                4211 non-null   object  \n",
      " 2   gender                                4211 non-null   category\n",
      " 3   age                                   4211 non-null   category\n",
      " 4   pers_extraverted_enthusiastic         4211 non-null   Int64   \n",
      " 5   pers_critical_quarrelsome             4211 non-null   Int64   \n",
      " 6   pers_dependable_self-disciplined      4211 non-null   Int64   \n",
      " 7   pers_anxious_easily_upset             4211 non-null   Int64   \n",
      " 8   pers_open_to_new_experiences_complex  4211 non-null   Int64   \n",
      " 9   pers_sympathetic_warm                 4211 non-null   Int64   \n",
      " 10  pers_disorganized_careless            4211 non-null   Int64   \n",
      " 11  pers_reserved_quiet                   4211 non-null   Int64   \n",
      " 12  pers_calm_emotionally_stable          4211 non-null   Int64   \n",
      " 13  pers_conventional_uncreative          4211 non-null   Int64   \n",
      " 14  prep_level                            4211 non-null   float32 \n",
      " 15  qual_reasons                          4189 non-null   object  \n",
      " 16  el_lbal_anx                           4211 non-null   Int64   \n",
      " 17  el_lbal_sat                           4211 non-null   Int64   \n",
      " 18  el_lcnt_com                           4211 non-null   Int64   \n",
      " 19  el_lcnt_psy                           4211 non-null   Int64   \n",
      " 20  el_lcon_inc                           4211 non-null   Int64   \n",
      " 21  el_lcon_soc                           4211 non-null   Int64   \n",
      " 22  el_lcont_con                          4211 non-null   Int64   \n",
      " 23  el_lcont_imp                          4211 non-null   Int64   \n",
      " 24  el_lgen                               4211 non-null   Int64   \n",
      " 25  el_ljou_opt                           4211 non-null   Int64   \n",
      " 26  el_ljou_pro                           4211 non-null   Int64   \n",
      " 27  el_lres_fin                           4211 non-null   Int64   \n",
      " 28  el_lres_ski                           4211 non-null   Int64   \n",
      " 29  el_ltra_aut                           4211 non-null   Int64   \n",
      " 30  el_ltra_des                           4211 non-null   Int64   \n",
      " 31  wfl_lcarprom_d                        4211 non-null   Int64   \n",
      " 32  wfl_lcollea                           4211 non-null   Int64   \n",
      " 33  wfl_lenjhyb                           4211 non-null   Int64   \n",
      " 34  wfl_lexcess_wk                        4210 non-null   Int64   \n",
      " 35  wfl_lfin_lair                         4210 non-null   Int64   \n",
      " 36  wfl_llearn_dev                        4211 non-null   Int64   \n",
      " 37  wfl_lmean_full                        4210 non-null   Int64   \n",
      " 38  wfl_lpoorman                          4211 non-null   Int64   \n",
      " 39  wfl_ltoxic                            4211 non-null   Int64   \n",
      " 40  wfl_luse_skills                       4210 non-null   Int64   \n",
      " 41  wfl_lwellcomp                         4211 non-null   Int64   \n",
      " 42  es_fbal_anx                           4210 non-null   float32 \n",
      " 43  es_fbal_sat                           4211 non-null   float32 \n",
      " 44  es_fcnt_com                           4211 non-null   float32 \n",
      " 45  es_fcnt_psy                           4211 non-null   float32 \n",
      " 46  es_fcon_inc                           4211 non-null   float32 \n",
      " 47  es_fcon_soc                           4209 non-null   float32 \n",
      " 48  es_fcont_con                          4210 non-null   float32 \n",
      " 49  es_fcont_imp                          4210 non-null   float32 \n",
      " 50  es_fgen                               4210 non-null   float32 \n",
      " 51  es_fjou_opt                           4211 non-null   float32 \n",
      " 52  es_fjou_pro                           4209 non-null   float32 \n",
      " 53  es_fres_fin                           4206 non-null   float32 \n",
      " 54  es_fres_ski                           4211 non-null   float32 \n",
      " 55  es_ftra_aut                           4211 non-null   float32 \n",
      " 56  es_ftra_des                           4210 non-null   float32 \n",
      " 57  wfs_fcarprom                          4210 non-null   float32 \n",
      " 58  wfs_fcollea                           4211 non-null   float32 \n",
      " 59  wfs_fenjhyb                           4211 non-null   float32 \n",
      " 60  wfs_fexcess_wk                        4211 non-null   float32 \n",
      " 61  wfs_ffin_fair                         4211 non-null   float32 \n",
      " 62  wfs_flearn_dev                        4211 non-null   float32 \n",
      " 63  wfs_fmean_full                        4211 non-null   float32 \n",
      " 64  wfs_fpoorman                          4211 non-null   float32 \n",
      " 65  wfs_ftoxic                            4208 non-null   float32 \n",
      " 66  wfs_fuse_skills                       4209 non-null   float32 \n",
      " 67  wfs_fwellcomp                         4211 non-null   float32 \n",
      "dtypes: Int64(36), category(2), float32(27), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0693de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VARIABLE RANGES AND UNIQUE VALUES ===\n",
      "country: 6 unique values\n",
      "Values: ['FR' 'DE' 'SP' 'US' 'IT' 'UK']\n",
      "sector: 4 unique values\n",
      "Values: ['Tech' 'Fin' 'Pharma' 'Energy']\n",
      "gender: 5 unique values\n",
      "Values: ['Female', 'Male', 'Non-Binary / Non-Conforming', 'Other', 'Prefer Not to Answer']\n",
      "age: 3 unique values\n",
      "Values: ['18-24', '25-40', '41-64']\n",
      "pers_extraverted_enthusiastic: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[5, 2, 4, 7, 6, 3, 1]\n",
      "Length: 7, dtype: Int64\n",
      "pers_critical_quarrelsome: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[1, 2, 3, 6, 5, 4, 7]\n",
      "Length: 7, dtype: Int64\n",
      "pers_dependable_self-disciplined: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[7, 6, 1, 2, 3, 5, 4]\n",
      "Length: 7, dtype: Int64\n",
      "pers_anxious_easily_upset: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[3, 4, 5, 2, 6, 7, 1]\n",
      "Length: 7, dtype: Int64\n",
      "pers_open_to_new_experiences_complex: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[7, 2, 4, 6, 3, 5, 1]\n",
      "Length: 7, dtype: Int64\n",
      "pers_sympathetic_warm: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[7, 2, 1, 6, 4, 5, 3]\n",
      "Length: 7, dtype: Int64\n",
      "pers_disorganized_careless: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[1, 5, 7, 3, 4, 2, 6]\n",
      "Length: 7, dtype: Int64\n",
      "pers_reserved_quiet: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[6, 5, 4, 2, 7, 3, 1]\n",
      "Length: 7, dtype: Int64\n",
      "pers_calm_emotionally_stable: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[6, 7, 4, 2, 5, 1, 3]\n",
      "Length: 7, dtype: Int64\n",
      "pers_conventional_uncreative: 7 unique values\n",
      "Values: <IntegerArray>\n",
      "[2, 1, 3, 5, 7, 4, 6]\n",
      "Length: 7, dtype: Int64\n",
      "prep_level: range 1.0 to 10.0, 88 unique values\n",
      "qual_reasons: 4107 unique values\n",
      "Values: ['Je suis prête à m’engager, organise'\n",
      " 'Jeune diplôme je suis prête à entrer dans le monde professionnel sur un emploi stable et sur du long terme'\n",
      " 'La nouvelle technologie, les nouveaux moyens mit en place…' ...\n",
      " 'Italian reasons' 'El Reasons' 'Reasons Spanish']\n",
      "el_lbal_anx: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[50, -100, 25, 0, -25, -75, 75, -50, 100]\n",
      "Length: 9, dtype: Int64\n",
      "el_lbal_sat: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 75, 0, 50, -75, 25, -100, -25, -50]\n",
      "Length: 9, dtype: Int64\n",
      "el_lcnt_com: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[0, 25, 50, -50, -25, 75, 100, -75, -100]\n",
      "Length: 9, dtype: Int64\n",
      "el_lcnt_psy: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 50, 0, -50, -25, 25, -100, 75, -75]\n",
      "Length: 9, dtype: Int64\n",
      "el_lcon_inc: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 25, 50, -25, 0, 75, -50, -75, -100]\n",
      "Length: 9, dtype: Int64\n",
      "el_lcon_soc: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[-100, 50, 25, -75, -50, 0, 75, -25, 100]\n",
      "Length: 9, dtype: Int64\n",
      "el_lcont_con: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[0, 75, 100, -25, 25, 50, -50, -75, -100]\n",
      "Length: 9, dtype: Int64\n",
      "el_lcont_imp: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 50, 25, -50, -100, -25, 75, 0, -75]\n",
      "Length: 9, dtype: Int64\n",
      "el_lgen: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, -25, 75, 25, 50, 0, -100, -75, -50]\n",
      "Length: 9, dtype: Int64\n",
      "el_ljou_opt: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[50, 100, 25, 0, 75, -25, -50, -100, -75]\n",
      "Length: 9, dtype: Int64\n",
      "el_ljou_pro: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[75, 50, 100, 0, -50, -100, 25, -25, -75]\n",
      "Length: 9, dtype: Int64\n",
      "el_lres_fin: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[75, 50, 0, 100, -50, 25, -25, -100, -75]\n",
      "Length: 9, dtype: Int64\n",
      "el_lres_ski: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 75, -25, -75, 50, 25, 0, -50, -100]\n",
      "Length: 9, dtype: Int64\n",
      "el_ltra_aut: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 25, 50, 75, 0, -100, -75, -50, -25]\n",
      "Length: 9, dtype: Int64\n",
      "el_ltra_des: 9 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 50, 75, -25, 0, 25, -100, -50, -75]\n",
      "Length: 9, dtype: Int64\n",
      "wfl_lcarprom_d: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 0, 50, 75, 25]\n",
      "Length: 5, dtype: Int64\n",
      "wfl_lcollea: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[0, 25, 50, 75, 100]\n",
      "Length: 5, dtype: Int64\n",
      "wfl_lenjhyb: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[75, 25, 50, 100, 0]\n",
      "Length: 5, dtype: Int64\n",
      "wfl_lexcess_wk: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 75, 0, 25, 50, <NA>]\n",
      "Length: 6, dtype: Int64\n",
      "wfl_lfin_lair: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[0, 25, 50, 100, 75, <NA>]\n",
      "Length: 6, dtype: Int64\n",
      "wfl_llearn_dev: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 50, 75, 0, 25]\n",
      "Length: 5, dtype: Int64\n",
      "wfl_lmean_full: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 50, 0, 75, 25, <NA>]\n",
      "Length: 6, dtype: Int64\n",
      "wfl_lpoorman: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[25, 75, 50, 100, 0]\n",
      "Length: 5, dtype: Int64\n",
      "wfl_ltoxic: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 50, 25, 75, 0]\n",
      "Length: 5, dtype: Int64\n",
      "wfl_luse_skills: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 75, 25, 0, 50, <NA>]\n",
      "Length: 6, dtype: Int64\n",
      "wfl_lwellcomp: 5 unique values\n",
      "Values: <IntegerArray>\n",
      "[100, 0, 50, 75, 25]\n",
      "Length: 5, dtype: Int64\n",
      "es_fbal_anx: range -94.44444274902344 to 98.88888549804688, 325 unique values\n",
      "es_fbal_sat: range -96.66666412353516 to 98.88888549804688, 335 unique values\n",
      "es_fcnt_com: range -98.88888549804688 to 97.77777862548828, 338 unique values\n",
      "es_fcnt_psy: range -97.22222137451172 to 98.88888549804688, 327 unique values\n",
      "es_fcon_inc: range -98.88888549804688 to 97.77777862548828, 342 unique values\n",
      "es_fcon_soc: range -98.88888549804688 to 97.77777862548828, 317 unique values\n",
      "es_fcont_con: range -96.66666412353516 to 97.77777862548828, 329 unique values\n",
      "es_fcont_imp: range -98.88888549804688 to 98.88888549804688, 331 unique values\n",
      "es_fgen: range -96.66666412353516 to 98.88888549804688, 310 unique values\n",
      "es_fjou_opt: range -96.66666412353516 to 96.66666412353516, 339 unique values\n",
      "es_fjou_pro: range -98.88888549804688 to 96.66666412353516, 329 unique values\n",
      "es_fres_fin: range -98.88888549804688 to 98.88888549804688, 327 unique values\n",
      "es_fres_ski: range -98.88888549804688 to 98.88888549804688, 320 unique values\n",
      "es_ftra_aut: range -96.11111450195312 to 98.88888549804688, 329 unique values\n",
      "es_ftra_des: range -98.88888549804688 to 98.88888549804688, 329 unique values\n",
      "wfs_fcarprom: range 0.0 to 100.0, 177 unique values\n",
      "wfs_fcollea: range 0.0 to 100.0, 187 unique values\n",
      "wfs_fenjhyb: range 0.0 to 100.0, 189 unique values\n",
      "wfs_fexcess_wk: range 0.0 to 100.0, 185 unique values\n",
      "wfs_ffin_fair: range 0.0 to 100.0, 184 unique values\n",
      "wfs_flearn_dev: range 0.0 to 100.0, 174 unique values\n",
      "wfs_fmean_full: range 0.0 to 100.0, 180 unique values\n",
      "wfs_fpoorman: range 0.0 to 100.0, 189 unique values\n",
      "wfs_ftoxic: range 0.0 to 100.0, 185 unique values\n",
      "wfs_fuse_skills: range 0.0 to 100.0, 173 unique values\n",
      "wfs_fwellcomp: range 0.0 to 100.0, 183 unique values\n"
     ]
    }
   ],
   "source": [
    "data.describe(include='all')\n",
    "\n",
    "# get variable ranges and unique values\n",
    "print(\"\\n=== VARIABLE RANGES AND UNIQUE VALUES ===\")   \n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'category':\n",
    "        print(f\"{col}: {data[col].nunique()} unique values\")\n",
    "        print(f\"Values: {data[col].cat.categories.tolist()}\")\n",
    "    elif data[col].dtype in ['int64', 'float64', 'int8', 'float32']:\n",
    "        print(f\"{col}: range {data[col].min()} to {data[col].max()}, {data[col].nunique()} unique values\")\n",
    "    else:\n",
    "        print(f\"{col}: {data[col].nunique()} unique values\")\n",
    "        print(f\"Values: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf3fd1",
   "metadata": {},
   "source": [
    "### Scale Transformations\n",
    "\n",
    "**IMPORTANT:** We are transforming the original scales to standardized ranges for consistent interpretation across analyses. This maintains methodological consistency while allowing for comparable coefficient interpretation.\n",
    "\n",
    "**Original Scales:**\n",
    "- **Emotional Likert (el_)**: -100 to +100 (9 response points: -100, -75, -50, -25, 0, 25, 50, 75, 100)\n",
    "- **Workplace/Functional Likert (wfl_)**: 0 to 100 (5 response points: 0, 25, 50, 75, 100)  \n",
    "- **Emotional Fast Choice (es_)**: Approximately -100 to +100 (implicit continuous scores)\n",
    "- **Workplace/Functional Fast Choice (wfs_)**: Approximately 0 to 100 (implicit continuous scores)\n",
    "\n",
    "**Transformed Scales:**\n",
    "- **Emotional Likert → 1 to 9 scale**: More intuitive for coefficient interpretation\n",
    "- **Workplace Likert → 1 to 5 scale**: Matches typical 5-point Likert interpretation\n",
    "- **Emotional Fast Choice → -1 to +1 scale**: Normalized around zero for symmetry\n",
    "- **Workplace Fast Choice → 0 to 1 scale**: Normalized proportion scale\n",
    "\n",
    "These transformations preserve the relative ordering and spacing of responses while creating more interpretable coefficient magnitudes in regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scale transformations to create standardized predictor variables\n",
    "print(\"Applying scale transformations...\")\n",
    "print(\"Original ranges:\")\n",
    "\n",
    "# Show original ranges before transformation\n",
    "el_cols = [col for col in data.columns if col.startswith('el_')]\n",
    "wfl_cols = [col for col in data.columns if col.startswith('wfl_')]\n",
    "es_cols = [col for col in data.columns if col.startswith('es_')]\n",
    "wfs_cols = [col for col in data.columns if col.startswith('wfs_')]\n",
    "\n",
    "print(f\"Emotional Likert (el_): {data[el_cols].min().min()} to {data[el_cols].max().max()}\")\n",
    "print(f\"Workplace Likert (wfl_): {data[wfl_cols].min().min()} to {data[wfl_cols].max().max()}\")\n",
    "print(f\"Emotional Fast Choice (es_): {data[es_cols].min().min():.2f} to {data[es_cols].max().max():.2f}\")\n",
    "print(f\"Workplace Fast Choice (wfs_): {data[wfs_cols].min().min():.2f} to {data[wfs_cols].max().max():.2f}\")\n",
    "\n",
    "# Transform emotional Likert: -100 to +100 with 9 points → 1 to 9\n",
    "for col in el_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = (data[col] + 100) / 25 + 1\n",
    "\n",
    "# Transform workplace Likert: 0 to 100 with 5 points → 1 to 5  \n",
    "for col in wfl_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col] / 25 + 1\n",
    "\n",
    "# Transform emotional fast choice: -100 to +100 → -1 to +1\n",
    "for col in es_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col] / 100\n",
    "\n",
    "# Transform workplace fast choice: 0 to 100 → 0 to 1\n",
    "for col in wfs_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col] / 100\n",
    "\n",
    "print(\"\\nTransformed ranges:\")\n",
    "print(f\"Emotional Likert (el_): {data[el_cols].min().min():.2f} to {data[el_cols].max().max():.2f}\")\n",
    "print(f\"Workplace Likert (wfl_): {data[wfl_cols].min().min():.2f} to {data[wfl_cols].max().max():.2f}\")\n",
    "print(f\"Emotional Fast Choice (es_): {data[es_cols].min().min():.2f} to {data[es_cols].max().max():.2f}\")\n",
    "print(f\"Workplace Fast Choice (wfs_): {data[wfs_cols].min().min():.2f} to {data[wfs_cols].max().max():.2f}\")\n",
    "\n",
    "print(\"\\nScale transformations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae529c",
   "metadata": {},
   "source": [
    "### Ongoing Questions\n",
    "\n",
    "- Not understanding the fast choice responses? Why are some negative? What does it substantively represent? Not understanding the ranges at the moment\n",
    "- Fast choice are implicit scores? Whereas likert are explicit scores? What does this signify?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
